---
title: "TMDB Box revenue prediction"
author: "Nguyen Bao Long"
date: "8/19/2019"
output:
  word_document: default
  html_document: default
---

\newpage

```{r setup, include=FALSE}
# set up environment, standardize figure output

options(tinytex.verbose = TRUE)
knitr::opts_chunk$set(echo = TRUE, fig.height = 3.5, fig.width = 5,
                      fig.align = "center")
```

```{r, include=FALSE}
if(!require(matrixStats)) install.packages("matrixStats", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)

if(!require(Amelia)) install.packages("Amelia", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)

if(!require(gridExtra)) install.packages("gridExtra", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)

if(!require(tidyverse)) install.packages("tidyverse", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)

if(!require(caret)) install.packages("caret", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)

if(!require(kableExtra)) install.packages("kableExtra", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)

if(!require(TMDb)) install.packages("TMDb", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)

if(!require(GGally)) install.packages("GGally", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)
```


```{r import library, include=FALSE}
library(tidyverse)
library(caret)
library(matrixStats)
library(grDevices)
library(gridExtra)
library(Amelia)
library(DataExplorer)
library(knitr)
library(kableExtra)
library(lubridate)
library(corrplot)
library(TMDb)
library(GGally)
```


\newpage

# **Introduction**

## **Background**

This document is the second project's report in the course HarvardX: PH125.9x Data Science: Capstone project. Inspired by the Kaggle TMDb Box Office Competition [1], this document describes my solution to develop a machine learning model to predict movie's worldwide box office revenue.

* Section 1: describe project background, goal and overview on the dataset.

* Section 2: describe the data exploratory analysis, what's insights gained and concept of predicting model.

* Section 3: evaluate and discuss on the result of the model.

* Section 4: conclusion describe a brief summary of the report.

## **Overview**

### **TMDB Box Office Competition**

*"Can you predict a movie's worldwide box office revenue?"*

On February $9^{th}, 2019$ Kaggle launch a competition, using the TMDB Box Office dataset to predict a movie's worldwide box office revenue. This competition was end by May $31^{th}$, 2019 which total 1398 teams, 1618 competitors and 19,034 entries. Here come the introduction from Kaggle:

*"In a worldâ€¦ where movies made an estimated $41.7 billion in 2018, the film industry is more popular than ever. But what movies make the most money at the box office? How much does a director matter? Or the budget? For some movies, it's "You had me at 'Hello.'" For others, the trailer falls short of expectations and you think "What we have here is a failure to communicate."*

*In this competition, you're presented with metadata on over 7,000 past films from The Movie Database to try and predict their overall worldwide box office revenue. Data points provided include cast, crew, plot keywords, budget, posters, release dates, languages, production companies, and countries. You can collect other publicly available data to use in your model predictions, but in the spirit of this competition, use only data that would have been available before a movie's release."*

### **Competition's dataset**

The dataset used in this competition has been collected from the Movies Database (https://www.themoviedb.org/). The movie details, credits and keywords have been collected from the TMDB Open API. This competition uses the TMDB API but is not endorsed or certified by TMDB. Their API also provides access to data on many additional movies, actors and actresses, crew members, and TV shows.

This data contain 7398 movies and a variety of metadata. Movies are labeled with id. Data points include cast, crew, plot keywords, budget, posters, release dates, languages, production companies, and countries. The dataset was subset to 2 dataset, the `train.csv` has 3000 movies and `test.csv` with 4398 movies.

### **Additional dataset**

Since this competition allowed for publicly available data, I retrieved the first additional data by from TMDB website (https://www.themoviedb.org/?language=en-US). 

The TMDb packages was also available in R libraries (https://cran.r-project.org/web/packages/TMDb/index.html) which you can retrieve other features for this competition. 

The instruction to retrieve data from TMDb website is reference from following link (http://www.planetanalytics.in/2017/05/how-to-extract-movie-data-from-movie.html).

The second additional data is from wikipedia, using web scrapping techniques by rvest package.

**Competition evaluation**

To evaluate results in Kaggle's competition, competitors must develop machine learning model to predict the international box office revenue for each movie. For each id in the test set, competitors must predict the value of the revenue variable. 

Submissions are evaluated on Root-Mean-Squared-Logarithmic-Error (RMSLE) between the predicted value and the actual revenue. Logs are taken to not overweight blockbuster revenue movies.

Since this competition completed on May $31^{st}$, following is the final public leaderboard.

```{r, fig.width=8, include=FALSE}
# import leaderboard data
url_leaderboard <- url("https://raw.githubusercontent.com/billynguyenlss/TMDB-Box/master/data/tmdb-publicleaderboard.csv")
tmdb_leaderboard <- read.csv(url_leaderboard, na.strings=c("", '#N/A', '[]', '0'))

tmdb_leaderboard$SubmissionDate <- ymd_hms(tmdb_leaderboard$SubmissionDate)
```

```{r, include=FALSE}
final_board <- tmdb_leaderboard %>% group_by(TeamName) %>%
  summarize(submitted_times = n(),
            best_score = min(Score)) %>% arrange(best_score)
```

```{r, include=FALSE}
top_10 <- final_board[140,3]
```

```{r, fig.width=8}
final_board %>% 
  ggplot(aes(best_score)) +
  geom_histogram(fill = "steel blue", binwidth = 0.1) +
  scale_x_continuous(minor_breaks = seq(0, 30, 1)) +
  geom_vline(xintercept = 1.7068, color = "red") +
  geom_text(aes(x = 5, y = 240, label = "top 10% (RMSLE < 1.7068)"), color = "red") +
  labs(title = "TMDB Box office competition final leaderboard",
       caption = "Data source from Kaggle's TMDB Box office competition public leaderboard")
```


```{r}
final_board %>% head(10) %>%
  kable(caption = "Top 10 best Score in TMDB Box Office Competition") %>%
  kable_styling(latex_options = c("HOLD_position"))
```


## **My objective**

My objective are:

1) To develop a machine learning model to predict the internaltion box office revenue and reduce RMSLE as much as possible.

2) To practice data exploratory analysis skills, text mining using `stringr`, data visualization using `ggplot2`, summarize and transform data using `dplyr`, web scrapping using `rvest`.

3) To improve my business writing and reporting skills, using `rmarkdown` and kable function.

## **Project methodology**

This project has 4 main steps:

+ Step 1 **data exploratory analysis**: exploring, cleaning, visualizing the data to have an overview with-in and between the variables, what's insights gained after analysis. Main package for this step is tidyverse, to handle the cleaning, exploring and visualizing tasks.

+ Step 2:**features engineering**  Inputs for this step are insights gained in previous step, and some best score kernels in Kaggle. Below are some kernel which inspired me to complete my report.

  * Zero92's kernel (RMSLE = 1.6998) https://www.kaggle.com/zero92/tmdb-prediction
  * tavoosi's kernel (RMSLE = 1.95841) https://www.kaggle.com/tavoosi/predicting-box-office-revenue-with-random-forest

**Noted:** even the Kaggle mention *"use only data that would have been available before a movie's release"*, I found that many competitors used the vote count and vote average in their model, which should be available after the movie's release.
  
+ Step 3: **modeling and performance evaluation**. we develop predicting model using Caret package and evaluate its effectiveness by using RMLSE. The true revenue for this step is received from TMDb, using API and package TMDb. The RMLSE are calculated by following formula:

$ RMLSE = \sqrt{\frac{\sum_{i = 1}^{n} (log y_{i} - log \hat{y}_{i})^{2}}{n}} $

```{r}
# write function RMLSe to evaluate modeling performance
RMLSE <- function(predicted_revenue, true_revenue){
  sqrt(mean((log(true_revenue)- log(predicted_revenue))^2))
}
```


# **Data exploratory analysis**

## **Data preparation**

Download data from my github repo and import to R global environment.

**Competition's dataset**

```{r}
# download raw data from my github repo

url_train <- url("https://raw.githubusercontent.com/billynguyenlss/TMDB-Box/master/data/train.csv")
train_set <- read.csv(url_train, na.strings=c("", '#N/A', '[]', '0'))

url_test <- url("https://raw.githubusercontent.com/billynguyenlss/TMDB-Box/master/data/test.csv")
test_set <- read.csv(url_test, na.strings=c("", '#N/A', '[]', '0'))

url_sample_submission <- url("https://raw.githubusercontent.com/billynguyenlss/TMDB-Box/master/data/sample_submission.csv")
sample_submission <- read.csv(url_sample_submission, na.strings=c("", '#N/A', '[]', '0'))
```

Combine train and test dataset to one data to save time for features preprocessing.

```{r combine train test data, warning=FALSE}
# combine train_set and test_set to reduce time to pre-processing data
train_set <- train_set %>% mutate_if(is.factor, as.character)
test_set <- test_set %>% mutate_if(is.factor, as.character)
df <- bind_rows(train_set, test_set)
```

**Additional dataset**

```{r}
# download additional data from my github repo

url_additional <- url("https://raw.githubusercontent.com/billynguyenlss/TMDB-Box/master/data/personal%20additional%20data/full_additional_features_2.csv")
addition_data <- read.csv(url_additional, na.strings=c("", '#N/A', '[]', '0'))
```

```{r}
str(addition_data)
```


Because the true revenue was available on the TMDb dataset, I extract it to a vector named `test_y` for final modeling performance evaluation.

```{r}
# extract the true_rating value from additional data
test_y <- test_set %>% left_join(addition_data, by = "imdb_id") %>%
  select(new_revenue)
test_y$new_revenue[is.na(test_y$revenue)] <- median(test_y$revenue, na.rm = T)
test_y <- test_y$new_revenue
```

## **Data overview**

The **train_set** have 3000 observations of 23 variables.

```{r}
dim(train_set)
```

The **test_set** has 4398 observations of 22 variables.

```{r}
dim(test_set)
```

Lets take a glimpse at our data to get a feel of how it looks like.

```{r}
glimpse(df)
```

We can classify and summarize the variables to data type continuous, discrete and date/time. I don't include the first column `id` in this table due to its meaning is only ordering number. The variables `imdb_id` is the identified number in imdb system, so I don't include it in below table as well. But please notice that the `imdb_id` is important to retrieve additional data from TMDb database.

Continuous variables    Discrete variables      Date/time     
----------------------  ----------------------  ------------- 
budget                  belongs_to_collection   release_date
popularity              genres
runtime                 homepage
revenue                 original_language
                        original_title
                        overview
                        poster_path
                        production_companies
                        production_contries
                        spoken_languages
                        tagline
                        Keywords
                        cast
                        crew

**NA value**

```{r, fig.height=5}
plot_missing(train_set)
```

`belongs_to_collection`, `homepage`, `budget`, `tagline`, `Keywords`, `production_companies` have high NA value ratio compare to others.

# **Data exploratory analysis**

## **Revenue**

Summary table of revenue:

```{r}
average_revenue <- mean(df$revenue, na.rm = TRUE)
summary(train_set$revenue)
```

Let's see performance of the first naive model using the average revenue as the predicted revenue.

```{r}
RMLSE(average_revenue, train_set$revenue)
```


```{r, fig.width=8, fig.height=3.5}
grid.arrange(
train_set %>% ggplot(aes(revenue)) +
  geom_histogram(fill = "steel blue", color = "white") +
  geom_vline(aes(xintercept = average_revenue), color = "red") +
  labs(title = "frequency of revenue",
       caption = "Figure - histogram using ggplot2 in train_set"),

train_set %>% ggplot(aes(y = revenue)) +
  geom_boxplot(fill = "steel blue") +
  labs(title = "boxplot of revenue",
       caption = "Figure - boxplot using ggplot2 in train_set") +
  coord_flip(),
ncol = 2)
```

Not many movies have great revenue.
`r 100*round(mean(train_set$revenue <= average_revenue),3)`
% movies in the training dataset have revenue lower than the average revenue. Only
`r 100 - 100*round(mean(train_set$revenue <= average_revenue),3)`
% movies have revenue greater than the average revenue.

### **release_date**

Now we take a look on the `revenue` change by time.

```{r}
head(df$release_date)
```

Now convert release_date from current type "character" to "date-time".

```{r}
df$release_date <- mdy(df$release_date)
summary(df$release_date)
```

The latest release_date is "2068-12-30" which is impossible. There are total
`r df %>% filter(release_date >= today()) %>% nrow`
days later than this time I am doing this report on August $27^{th}$, 2019.
We also have 1 NA value in the `release_date`. 

To correct the `release_date`, I use the release date in additional data set. Now we joining the addition data to our dataset.

```{r}
# left joining the addition data into df
df <- df %>% left_join(addition_data[,c(1,2,3,7:13)], by = "imdb_id")
df$new_release_date <- as.character(df$new_release_date)

# replace wrong release data
df <- df %>% 
  mutate(new_release_date = mdy(new_release_date)) %>%
  mutate(release_date = ifelse(release_date >= ymd("2019-05-31"),
                               new_release_date, release_date)) %>%
  mutate(release_date = ifelse(is.na(release_date),
                               new_release_date, release_date)) %>%
  mutate(release_date = as_date(release_date))
```

Calculate the `release_year` and `release_month`.

```{r}
df$release_year <- year(df$release_date)
df$release_month <- month(df$release_date)
```

```{r, fig.width=7.5, fig.height=3.5}
grid.arrange(
  df %>% 
    ggplot(aes(release_year)) +
    geom_bar(fill = "steel blue") +
    labs(title = "Number of movies by release year"),
  
  df %>% ggplot(aes(release_month)) +
    geom_bar(fill = "steel blue", color = "white") +
    labs(title = "Number of movies by release month"),

  ncol = 2
)
```

```{r}
summary(df$release_date)
```

The movies box office growth slowly before decade 1980s , 25% movies released in 
`r 1993 - 1921`
years from 1921 to 1993, and 25% others movies released in
`r 2004 - 1993`
years from 1993 to 2004. 

```{r,fig.width=8}
df <- df %>% mutate(revenue_status = ifelse(is.na(revenue),"unknown revenue","known revenue")) %>%
  mutate(revenue_status = factor(revenue_status))

grid.arrange(
    df %>% 
    group_by(release_year, revenue_status) %>%
    summarize(total_budget = sum(budget, na.rm = T)) %>%
    ggplot(aes(release_year, total_budget, fill = revenue_status)) +
    geom_col(color = "white") +
    scale_fill_manual(values = c("grey","steel blue")) +
    theme_classic()+
    theme(legend.position = "none") + ylim(0,1.5e10)+
      labs(title = "budget change by time"),
  
  df %>% group_by(release_year) %>%
    summarize(total_known_revenue = sum(revenue, na.rm = T)) %>%
    ggplot(aes(release_year, total_known_revenue)) +
    geom_col(color = "white", fill = "steel blue") +
    theme_classic()+
    theme(legend.position = "none")+ ylim(0,1.5e10) +
    labs(title = "known revenue change by time"),
  
  ncol = 2)
```

Based on the ratio of unknown revenue by release year and current revenue, we can estimate the total unknown revenue.

## **Revenue vs continuous variables**

The continuous variables include id, budget, popularity, runtime, revenue. The `id` have no meaning, so we will remove it out of our dataset.

```{r, fig.height=5, fig.width=8}
# overview graph on budget, revenue, runtime, popularity, ROI
grid.arrange(
  train_set %>% ggplot(aes(budget)) +
    geom_histogram(fill = "steel blue", color = "white"),
  
  train_set %>% ggplot(aes(revenue)) +
    geom_histogram(fill = "steel blue", color = "white"),
  
  train_set %>% ggplot(aes(runtime)) +
    geom_histogram(fill = "steel blue", color = "white"),
  
  train_set %>% ggplot(aes(popularity)) +
    geom_histogram(fill = "steel blue", color = "white"),
  
  # histogram ROI (filter out budget less than 50000)
  df %>% filter(budget > 50000) %>%
    mutate(ROI = (revenue - budget)/budget) %>%
    ggplot(aes(ROI)) +
    geom_histogram(fill = "steel blue", color = "white"),
  
  ncol = 3
)
```

```{r}
train_set %>% select(budget, revenue, runtime, popularity) %>%
  summary
```

The minimum budget 
`r min(train_set$budget, na.rm = TRUE)` 
and minimum revenue 
`r min(train_set$revenue, na.rm = TRUE)`
are impossible. Those numbers are outliers and have negative impact on our predicting models. To explore the budget and revenue, let's create a summary table as following:

```{r}
train_set %>% select(budget, revenue) %>%
  mutate(budget_status = ifelse(is.na(budget), "missing budget",
                                ifelse(budget <=1000,"low budget","normal budget")),
         revenue_status = ifelse(revenue <= 1000,"low revenue","normal revenue")) %>%
  group_by(budget_status, revenue_status) %>%
  summarize(count = n(),
            percent = 100*round(n()/nrow(train_set),3)) %>%
  mutate(remarks = ifelse(count == 5,"wrong budget",
                   ifelse(count == 34, "NA impact",
                   ifelse(count == 778, "NA impact",
                   ifelse(count == 10, "wrong revenue","-")))))
```

### **Budget**

The biggest impact come from NA value budgets. Since this competition allow to find the additional data, I scrapped data from wikipedia to correct the budget data. Because of the long processing time to scrapping and pre-processing, I copied but not allowed the scrapping code running in my report. You can refer to the scrapping code in Appendix section or download the completed file from my github repo. 

```{r}
url_wikipedia_budget <- url("https://raw.githubusercontent.com/billynguyenlss/TMDB-Box/master/wikipedia_us_budget.csv")
wikipedia_budget <- read.csv(url_wikipedia_budget, na.strings=c("", '#N/A', '[]', '0'))

wikipedia_budget$final_budget <- as.numeric(wikipedia_budget$final_budget)
mean(is.na(wikipedia_budget$final_budget))
```

Now joining the wikipedia to our data. The NA value now is only 0.12%.

```{r}
# joining addition wikipedia budget
df <- df %>% mutate(imdb_id = as.factor(imdb_id)) %>%
  left_join(wikipedia_budget[,c(1,2,5)],by = "imdb_id")

#replace low budget value
df <- df %>% 
  mutate(budget = ifelse(budget <= 1000 & revenue > 10000, final_budget, budget))

# replace NA budget value by wikipedia budget
df <- df %>% mutate(budget = ifelse(is.na(budget),
                                    final_budget, budget))
mean(is.na(df$budget))
```


```{r}
summary(df$budget)
```

Due to complication in budget exchange from different currencies to usd, as well as the exchange rate uncertainty during time, I replaced other NA values in `budget` by the median value by movie's release year.

```{r}
# create summary budget table by release year
budget_by_year <- df %>%
  group_by(release_year) %>%
  summarize(avg_budget = mean(budget, na.rm = T),
            median_budget = median(budget, na.rm = T))

# replace NA budget by median_budget value
df <- df %>% left_join(budget_by_year, by = "release_year") %>%
  mutate(budget = ifelse(is.na(budget), median_budget,
                         budget))

# re-check NA value in budget
mean(is.na(df$budget))
```

### **Runtime**

We replace the NA values in `runtime` by median value.

```{r}
df$runtime[is.na(df$runtime)] <- median(df$runtime, na.rm = T)
```

### **Popularity**

Popularity should represent for the number of audience respond to a movie. Now take an overview on the popularity:

```{r}
summary(df$popularity)
```

```{r}
df %>% group_by(release_year) %>%
  summarize(total_popularity = sum(popularity)) %>%
  ggplot(aes(release_year, total_popularity)) +
  geom_point(color = "steel blue")
```

The total popularity increased by release year and its trend look like the trend of budget vs release year and/or the trend of revenue vs release year. To normallize the change of popularity by time, I divide popularity by the average popularity per release year. The calculation is as following:

```{r}
# create the summarized table for popularity
popularity_sum <- df %>%
  group_by(release_year) %>%
  summarize(avg_popularity = mean(popularity, na.rm = T))

# create new normallized popularity
df <- df %>%
  left_join(popularity_sum, by = "release_year") %>%
  mutate(normallized_popularity = popularity/avg_popularity)
```

```{r}
# create 2nd summarize table for normallized_popularity
norm_popularity_sum <- df %>%
  group_by(release_year) %>%
  summarize(max_norm_pop = max(normallized_popularity, na.rm = T))

# add 2nd normallized popularity
df <- df %>%
  left_join(norm_popularity_sum, by = "release_year") %>%
  mutate(secon_norm_popularity = normallized_popularity/max_norm_pop)
```


Now we can evaluate the correlation between `revenue` and `budget`, `popularity`, `runtime`. We also add the `vote_count` and `vote_average` into our data.

### **ROI**

```{r}
df %>% mutate(ROI = (revenue - budget)/budget) %>%
  select(title, budget, normallized_popularity, revenue, ROI, vote_count, vote_average, popularity) %>%
  arrange(desc(ROI)) %>% head(10) %>%
  kable(caption = "Top movies with greatest ROI") %>%
  kable_styling(latex_options = c("HOLD_position"), position = "center")
```

The greatest ROI movie is "The Blair Witch Project". Reference from wikipedia, The Blair Witch Project grossed nearly $250 million worldwide on a modest budget of $60,000, making it one of the most successful independent films of all time (reference: https://en.wikipedia.org/wiki/The_Blair_Witch_Project).

### **Vote average and vote count**

The vote average and vote count are added from the additional data. `vote_average` represent for the average rating from audiences and `vote_count` represent for the accumulated number of vote given by audiences.

```{r}
summary(df[,c("vote_count","vote_average")])
```

Replace NA values by median.

```{r}
df$vote_count[is.na(df$vote_count)] <- median(df$vote_count, na.rm = T)
df$vote_average[is.na(df$vote_average)] <- median(df$vote_average, na.rm = T)
```


```{r, fig.width=7}
grid.arrange(
  df %>% ggplot(aes(vote_count)) +
    geom_histogram(fill = "steel blue",color = "white") +
    labs(title = "vote_count"),
  
  df %>% ggplot(aes(vote_average)) +
    geom_histogram(fill = "steel blue",color = "white") +
    labs(title = "vote_count"),
  
  ncol = 2
)
```

The distribution sharp of `vote_count` look like `budget` and `revenue`, while the vote_average look like the distribution sharp of `popularity`.

### **Correlation between variables**

Let's take a look on the correlation between `revenue` and `budget`, `popularity`, `runtime`.

```{r, warning=FALSE, fig.width=7, fig.height=7}
corrplot(cor(df[1:3000,c("revenue","budget","popularity","runtime",
                         "vote_count","vote_average",
                         "normallized_popularity", 
                         "secon_norm_popularity")]), type = "upper",
         method = "number")
```

## **Revenue vs discrete variables**

We have total 17 discrete variables. Some variables have no or less informative information which I decide not to analyze them in this report (`id`, `tagline`, `title`).

### **belongs_to_collection**

This variable have greatest number of NA values. There are `r 100*round(mean(is.na(df$belongs_to_collection)),4)`
% NA values and 
`r 100*round(mean(!is.na(df$belongs_to_collection)),4)`
% not-NA values. Let's take a look on the original values. 

```{r}
head(df$belongs_to_collection,5)
```

Not all strings are necessary, only the name of the collection is probably informative. We will remove all unnecessary strings by following code.

```{r}
# extract collection
df$collection <- str_extract(df$belongs_to_collection, 
            pattern = "(?<=name\\'\\:\\s{1}\\').+(?=\\'\\,\\s{1}\\'poster)")
df$collection[is.na(df$collection)] <- "no collection"

# quick review on the new feature collection
head(df$collection)
```

We have total
`r length(levels(factor(df$collection)))`
collection from both train_set and test_set.
To visualize the difference between movies belong to a collection and movies not belong to any collection, I add one new feature `collection_status` to classify a movie belong to a collection or not. The following code and figure represent for this difference.

```{r, fig.width=7, fig.height=3.5}
df <- df %>% mutate(collection_status = ifelse(collection == "no collection", 0, 1))

grid.arrange(
df %>% mutate(collection_status = factor(collection_status)) %>%
  ggplot(aes(x = collection_status, fill = collection_status)) +
  geom_bar() +
  theme_classic() +
  theme(legend.position = "none")+
  scale_fill_manual(values = c("grey","steel blue")) +
  labs(title = "frequency by collection status",
       caption = "Figure - barplot & boxplot using ggplot2,
       data df"),
  
df %>% mutate(collection_status = factor(collection_status)) %>%
  ggplot(aes(x = collection_status, revenue, fill = collection_status)) +
  geom_boxplot() +
  theme_classic() +
  theme(legend.position = "none") +
  scale_fill_manual(values = c("grey","steel blue")) +
  labs(title = "boxplot of collection status",
       caption = "0 - not belong to any collection,
        1 - belongs to collection"),

ncol = 2)
```

**Insight** almost movie didn't belong to any collection, but in average, a movie belongs to a collection has higher revenue than others. 

###  **genres**

Let's take a look on the genres. 

```{r}
head(df$genres)
```

A movie can have one genre or multiple genres. Each genre represents by following text *"{'id': 35, 'name': 'Comedy'}"* and separate by comma.

Replace NA value by "no genre".

```{r}
df$genres[is.na(df$genres)] <- "no genre"
```

We will extract the first genre from the genres strings to get the main genre for each movie. First, we will create a vector with the genres we want to extract. Next, we will extract the genres and add them to a new variable called `main_genre`.

```{r}
genres_matching_point <- "Comedy|Horror|Action|Drama|Documentary|Science Fiction|
              Crime|Fantasy|Thriller|Animation|Adventure|Mystery|War|Romance|Music|
              Family|Western|History|TV Movie|Foreign"

df$main_genre <- str_extract(df$genres, genres_matching_point)

df$main_genre[is.na(df$main_genre)] <- "no genre"
```

Now figure out the counting number and average revenue of each genre.

```{r, fig.width=7, fig.height=3.5}
grid.arrange(
df %>% 
  group_by(main_genre) %>%
  summarize(count = n()) %>%
  mutate(main_genre = reorder(main_genre, count),
         top_genre = ifelse(main_genre %in% c("Drama","Comedy","Action"),
                            "top count",
                            ifelse(main_genre %in% c("Adventure","Animation",
                            "Science Fiction"),"top revenue","common"))) %>%
  ggplot(aes(main_genre, count, fill = top_genre)) +
  geom_col() +
  scale_fill_manual(values = c("grey","steel blue","#FF9900"))+
  theme_classic() +
  coord_flip()+
  labs(title = "counting number of first genre") +
  theme(legend.position = "none"),

df %>% 
  group_by(main_genre) %>%
  summarize(avg_revenue = mean(revenue, na.rm = TRUE)) %>%
  mutate(main_genre = reorder(main_genre, avg_revenue),
         top_genre = ifelse(main_genre %in% c("Drama","Comedy","Action"),
                            "top count",
                            ifelse(main_genre %in% c("Adventure","Animation",
                            "Science Fiction"),"top revenue","common"))) %>%
  ggplot(aes(main_genre, avg_revenue, fill = top_genre)) +
  geom_col() +
  scale_fill_manual(values = c("grey","steel blue","#FF9900"))+
  theme_classic() +
  coord_flip()+
  labs(title = "average revenue of first genre") +
  theme(legend.position = "none"),

ncol = 2)
```

Top three common genres are *Drama, Comedy, Action*, but top three genres with greatest revenue are *Adventure, Animation, Science Fiction*.

Because a movie could have more than one genre, therefore we create the new variable to visualize the total genres of each movie.

```{r}
df$number_genres <- str_count(df$genres, pattern = "id")

df$number_genres[is.na(df$number_genres)] <- 0
```

Now we evaluate the correlation between budget, revenue on the number of genres.

```{r, fig.width=8, fig.height=3}
grid.arrange(
  df %>% 
    ggplot(aes(number_genres)) +
    geom_bar(fill = "steel blue"),
  
  df %>% group_by(number_genres) %>%
    summarize(avg_budget = mean(budget, na.rm = TRUE)) %>%
    ggplot(aes(number_genres, avg_budget)) +
    geom_col(fill = "steel blue"),
  
    df %>% group_by(number_genres) %>%
    summarize(avg_revenue = mean(revenue, na.rm = TRUE)) %>%
    ggplot(aes(number_genres, avg_revenue)) +
    geom_col(fill = "steel blue"),
  
  ncol = 3
)
```

**Insight** In average, movie's revenue and budget inreases proportionally with the number of genres. 

### **homepage**

Let's see the top 10 rows of homepage.

```{r}
head(df$homepage, 10)
```

There are total 
`r 100*round(mean(is.na(df$homepage)),4)`
% NA values and in this variable. Do a movie with homepage have better revenue than other movies? Now we add one new feature `homepage_status` with 2 levels "no homepage" and "has homepage" to answer above question.

```{r}
df$homepage_status <- ifelse(is.na(df$homepage), "no homepage","has homepage")
```

```{r}
df[1:3000,] %>% ggplot(aes(homepage_status, revenue, fill = homepage_status)) +
  geom_boxplot() +
  scale_fill_manual(values = c("steel blue","grey")) +
  theme_classic()+
  theme(legend.position = "none")
```

Has-homepage movies have higher revenue than no-homepage movies. 

### **original_language**

Create summary table of `original_language`.

```{r}
df %>% group_by(original_language) %>%
  summarize(count = n(),
            percent = 100*round(n()/nrow(df),3),
          avg_budget = mean(budget, na.rm = TRUE),
          avg_revenue = mean(revenue,na.rm = TRUE)) %>% 
  arrange(desc(count)) %>%
  head(10) %>%
  kable(caption = "summary table of top 10 original languages", digits = 0) %>%
  kable_styling(position = "center",
                latex_options = "HOLD_position")
```

There are total 
`r length(levels(factor(df$original_language)))`
levels and 
`r mean(is.na(df$original_language))`
NA values in the original_language. English (86%) is the most popular languages compare to other languages. To reduce the number of levels on this variables, I create a new ordinal feature to rank the original languages by its percent.

```{r}
df <- df %>% 
  mutate(original_language_sum = 
     ifelse(original_language %in% c("en"),5,
       ifelse(original_language %in% c("fr,hi","ru"),4,
         ifelse(original_language %in% c("es","ja","it","de","ko","zh","cn"),3,
            ifelse(original_language %in% c("af","ar","ca","is","ka","kn","mr","nb","vi"),1,2)))))
```

### **production_companies**

Let's take a look on the top 10 rows of production_companies.

```{r}
head(df$production_companies, 10)
```

There are total `r sum(is.na(df$production_companies))`
NA values, approximate
`r 100*round(mean(is.na(df$production_companies)),4)`
%. We see the famous production companies such as Paramount Pictures, Walt DIsney Pictures... and a movie could has more than one production companies. Each production company represent by a name (string) and an id (number). We firstly create a feature called `number_of_company` represent for the number of a movie's production companies, then we create another feature called `companies` content all production company's names of a movie.

```{r}
df$number_of_company <- str_count(df$production_companies, pattern = "\\'name\\'")

df$number_of_company[is.na(df$number_of_company)] <- median(df$number_of_company, na.rm = TRUE)
```

The second feature `companies` is created by following code.

```{r}
df$companies <- gsub("(\\[?\\{\\'name\\'\\:\\s\\')|(\\'\\,\\s{1}\\'id\\'\\:\\s{1}\\d+\\}\\]?)","",df$production_companies)
```

NA values are to be replaced by "no production companies info".

```{r}
df$companies[is.na(df$companies)] <- "no production companies info"
head(df$companies,10)
```

```{r}
production_companies <- strsplit(df$companies, ", ") 
production_companies <- unlist(production_companies, use.names=FALSE)

# production_companies <- production_companies[!duplicated(production_companies)]
head(production_companies,20)
```

```{r}
df$first_company <- gsub("\\,\\s{1}.*","",df$companies)
```

```{r}
first_company_summary <- df %>% group_by(first_company) %>%
  summarize(movies_per_company = n(),
            percent = 100*round(n()/nrow(df),3),
            avg_budget_per_company = mean(budget, na.rm = TRUE),
            avg_revenue_per_company = mean(revenue, na.rm = TRUE),
            ROI_per_company = round((mean(revenue, na.rm = TRUE) - 
                           mean(budget, na.rm = TRUE))/
                     mean(budget, na.rm = TRUE),3))
```

Let's look at top 10 companies with greatest number of movies. Movies with 'no production companies' have negative ROI, compare to others. Universal Pictures, Paramount Pictures, Twentieth Century Fox Film Corporation are top 3 number of movies.

```{r}
first_company_summary %>% arrange(desc(movies_per_company)) %>% head(10)
```

Now look at the average budget by first company. Heyday films, Mid Atlantic Films, Todman are top 3 greatest average budget.

```{r}
first_company_summary %>% arrange(desc(avg_budget_per_company)) %>% head(10)
```

Now look at the top average revenue companies. WingNut Films, 1492 Pictures, Blue Sky Studios have greatest average revenue compare to others, and the ROI are quite good (from 3.725 to 4.350).

```{r}
first_company_summary %>% arrange(desc(avg_revenue_per_company)) %>% head(10)
```

### **production_countries**

* First 10 values of `production_countries`. Each country represent by following text "{'iso_3166_1': 'US', 'name': 'United States of America'}" and separate by comma.

```{r}
head(df$production_countries, 10)
```

Now we remove all unnecessary strings and keep only the country's name in the new feature `country`.

```{r}
df$country <- gsub("(\\[\\{\\'.*name\\'\\:\\s{1}\\')|(\\'\\}\\])","",head(df$production_countries))

df$country[is.na(df$country)] <- "no country info"

table(df$country)
```

### **spoken_languages**

Let's take a look on top rows of `spoken_languages`.

```{r}
df$spoken_languages %>% head(10)
```

Each spoken language represent by following text "{'iso_639_1': 'en', 'name': 'English'}". We firstly create new feature `n_spoken_languages` represent for the number of spoken languages of a movie. Then we replace all unnecessary strings in the `spoken_languages`.

```{r}
df$n_spoken_languages <- str_count(df$spoken_languages, pattern = "name")

summary(df$n_spoken_languages)
```

We will replace the NA value by median.

```{r}
df$n_spoken_languages[is.na(df$n_spoken_languages)] <- median(df$n_spoken_languages, na.rm = T)
```

Translating to other languages cost money, and it's probably affect on movie's budget. But normally only famous movies were translated to other languages.

```{r, fig.width=8}
grid.arrange(
  df %>% mutate(n_spoken_languages = factor(n_spoken_languages)) %>%
  ggplot(aes(n_spoken_languages)) +
  geom_bar(fill = "steel blue", color = "white") +
    theme_classic(),
  
  df %>% mutate(n_spoken_languages = factor(n_spoken_languages)) %>%
  ggplot(aes(n_spoken_languages, budget)) +
  geom_boxplot(fill = "light blue") +
    theme_classic(),

df %>% mutate(n_spoken_languages = factor(n_spoken_languages)) %>%
  ggplot(aes(n_spoken_languages, revenue)) +
  geom_boxplot(fill = "light blue")+
  theme_classic(),

ncol = 3)
```

### **cast**

Let's take a look on `cast`. Each `cast` represent by following text "{'cast_id': 4, 'character': 'Lou', 'credit_id': '52fe4ee7c3a36847f82afae7', 'gender': 2, 'id': 52997, 'name': 'Rob Corddry', 'order': 0, 'profile_path': '/k2zJL0V1nEZuFT08xUdOd3ucfXz.jpg'}".

Now we create a new feature to summarize the number of cast of a movie.

```{r}
df$n_cast <- str_count(df$cast, pattern = "name")
```

Replace NA by median value.

```{r}
df$n_cast[is.na(df$n_cast)] <- median(df$n_cast, na.rm = T)
```

```{r, fig.width=7}
grid.arrange(
df %>% ggplot(aes(n_cast, budget)) +
  geom_point(color = "steel blue", alpha = 0.5)+
  geom_smooth(),

df %>% ggplot(aes(n_cast, revenue)) +
  geom_point(color = "steel blue", alpha = 0.5)+
  geom_smooth(),

ncol = 2)
```

We know in practice, people watch movies just because the movie have their idols or favor actors. I will extract the name of the first and second casts into two feature `first_cast` and `second_cast`.

```{r}
# extract the first cast
df$first_cast <- gsub("\\'\\,\\s\\'order\\'\\:\\s+0\\,.*",
                      "",
                      df$cast)

index <- str_which(df$first_cast,"profile")

df$first_cast <- gsub("\\'\\,\\s\\'order\\'\\:\\s+1\\,.*",
                      "",
                      df$first_cast)

df$first_cast <- str_extract(df$first_cast,"(?<=name\\'\\:\\s\\').+")
df$first_cast[1:10]
```

```{r}
# extract the second cast
df$second_cast <- gsub("\\'\\,\\s\\'order\\'\\:\\s{1}1\\,.*",
                      "",
                      df$cast)
df$second_cast <- gsub("\\[.*name\\'\\:\\s\\'","",
                       df$second_cast)

df$second_cast[index] <- gsub("\\'\\,\\s\\'order\\'\\:\\s{1}2\\,.*",
                      "",
                      df$cast)

df$second_cast[index] <- gsub("\\[.*name\\'\\:\\s\\'","",
                       df$second_cast)

head(df$second_cast,10)
```

```{r}
cast_summary <- df %>% 
  select(first_cast, second_cast, revenue, budget) %>%
  gather(1:2, key = "cast_order", value = "cast_name")

cast_summary$cast_name <- gsub("\\'\\,.*","",cast_summary$cast_name)

cast_summary <- cast_summary %>%
  group_by(cast_name) %>%
  summarize(movies_per_cast = n(),
            avg_revenue_per_cast = mean(revenue, na.rm = T))
```

Let's see top 10 casts with greatest number of movies.
```{r}
cast_summary %>% arrange(desc(movies_per_cast)) %>%
  head(10)
```

```{r}
cast_summary %>% arrange(desc(avg_revenue_per_cast)) %>%
  head(10)
```

### **crew**

Crew contain the production team of a movie, each member represents by following strings "{'credit_id': '59ac067c92514107af02c8c8', 'department': 'Directing', 'gender': 0, 'id': 1449071, 'job': 'First Assistant Director', 'name': 'Kelly Cantley', 'profile_path': None}" and separate with other members by comma.

**Noted** Because the length of strings is too long, I didn't copy it to this report.

Let's see how many members of a movies.

```{r}
df$n_crew <- str_count(df$crew, pattern = "name")

# replace NA value by median
df$n_crew[is.na(df$n_crew)] <- median(df$n_crew, na.rm = T)
```

```{r}
df %>% ggplot(aes(n_crew)) +
  geom_histogram(fill = "steel blue", color = "white") +
  theme_classic()
```

**Effect by director**

A film director controls a film's artistic and dramatic aspects and visualizes the screenplay (or script) while guiding the technical crew and actors in the fulfilment of that vision. The director has a key role in choosing the cast members, production design, and the creative aspects of filmmaking.(*Reference: https://en.wikipedia.org/wiki/Film_director*)

To evaluate impact from a director, we extract the director's name from `crew` by following code:211`

```{r}
# extract the director name
df$director <- gsub(".*\\'Director\\'\\,\\s\\'name\\'\\:\\s\\'","",df$crew)

df$director <- gsub("\\'\\,\\s.*","",df$director)

head(df$director)
```

Create a summary table for director.

```{r}
director_summary <- df %>% select(director, revenue) %>%
  group_by(director) %>%
  summarize(movies_per_director = n(),
            avg_revenue_per_director = mean(revenue, na.rm = T))
```

Top 10 director with greatest number of movies.

```{r}
director_summary %>% arrange(desc(movies_per_director)) %>%
  head(10)
```

Top 10 directors with greatest revenue.

```{r}
director_summary %>% arrange(desc(avg_revenue_per_director)) %>%
  head(10)
```

## **Features engineering**

### **collection revenue**

From previous section, we know movies belong to a collection have greater revenue than moves not belong to any collection. We will calculate the first new feature as average revenue per each collection.

```{r}
collection_revenue <- df %>% group_by(collection) %>%
  summarize(avg_revenue_per_collection = mean(revenue, na.rm = T))
```

The feature `aveg_revenue_per_collection` have 
`r 100*round(mean(is.na(collection_revenue$avg_revenue_per_collection)),4)`
% NA values in total. We replace it by the median value.

```{r}
index <- is.na(collection_revenue$avg_revenue_per_collection)

collection_revenue$avg_revenue_per_collection[index] <- 
  median(collection_revenue$avg_revenue_per_collection, na.rm = T)
```

Adding this to our data and see how much improvement on the results.

```{r}
df <- df %>% left_join(collection_revenue, by = "collection")
```

### **Production companies, cast, director**

Now we add the effect of production companies, casts and directors to our model.

**Production company**

```{r}
# left join the summary features by company
df <- df %>% left_join(first_company_summary[,c(1,2,5,6)], by = "first_company")
```

**First cast and second cast**

```{r}
# change cast_name to first_cast
names(cast_summary) <- c("first_cast","movies_per_cast","avg_revenue_per_cast")

# left join by first_cast
df <- df %>% left_join(cast_summary[,c(1,3)], by = "first_cast")

# change cast_name to second_cast
names(cast_summary) <- c("second_cast","movies_per_cast","avg_revenue_per_cast")

# left join by second cast
df <- df %>% left_join(cast_summary[,c(1,3)], by = "second_cast")
```

**Director**

```{r}
# left join by director
df <- df %>% left_join(director_summary, by = "director")
```

**Genres**

```{r}
genres <- levels(factor(df$main_genre))
```

```{r}
for (i in 1:19){
  df[,genres[i]] <- ifelse(str_detect(df$genres,genres[i]),
                           1,0)
}
```



Selecting the features.

```{r}
dat <- df %>% 
    mutate(x2 = budget*normallized_popularity,
         x3 = budget*vote_average,
         x4 = budget*secon_norm_popularity) %>%
  select(revenue,
         collection_status,
         #vote_count, vote_average,
         release_year, release_month, number_of_company,
         n_spoken_languages, n_cast, original_language_sum,
         n_crew, avg_revenue_per_director,
         x2,x4,68:79,81:83,85:86)

```




```{r}
head(dat)
```


Review the NA values.

```{r}
plot_missing(dat)
```

Replace NA values by median.

```{r}
for (i in 2:(ncol(dat))){
  dat[is.na(dat[,i]),i] <- median(dat[,i], na.rm = T)
}
```

**Correlation plot**

```{r, fig.width=7, fig.height=7}
corrplot(cor(dat[1:3000,]), type = "upper", method = "ellipse")
```

# **Modeling**

Before process modeling, we transform the revenue, budget, av_revenue_per_director, x2, x4 by logarit 10.

```{r}
dat$revenue <- log10(dat$revenue + 1)
dat$avg_revenue_per_director <- log10(dat$avg_revenue_per_director + 1)
dat$x2 <- log10(dat$x2 + 1)
# dat$x3 <- log10(dat$x3 + 1)
dat$x4 <- log10(dat$x4 + 1)

head(dat)
```

We use randorm forest (rf), support vector machine (svmLinear), gradient linear model boosting (glmboost) and linear model (lm) for modeling.

```{r}
fit_rf <- train(revenue ~ ., 
             data = dat[1:3000,],
             method = "rf",
             trControl = trainControl(method = "cv",
                                      number = 5,
                                      p = 0.8))

fit_svm <- train(revenue~.,
                 data = dat[1:3000,],
                 method = "svmLinear",
                 trControl = trainControl(method = "cv",
                                      number = 5,
                                      p = 0.8))


fit_glmboost <- train(revenue~.,
                 data = dat[1:3000,],
                 method = "glmboost",
                 trControl = trainControl(method = "cv",
                                      number = 5,
                                      p = 0.8))

fit_lm <- train(revenue~.,
                 data = dat[1:3000,],
                 method = "lm",
                 trControl = trainControl(method = "cv",
                                      number = 5,
                                      p = 0.8))
```



```{r}
data.frame(method = c("rf","svm","glmboost","lm"),
           RMSLE =c(min(fit_rf$results$RMSE),
                    min(fit_svm$results$RMSE),
                    min(fit_glmboost$results$RMSE),
                    min(fit_lm$results$RMSE)),
           Rsquared = c(max(fit_rf$results$Rsquared),
                        max(fit_svm$results$Rsquared),
                        max(fit_svm$results$Rsquared),
                        max(fit_lm$results$Rsquared)))
```

```{r}
# calculate predicted revenue

yhat_rf <- predict(fit_rf, newdata = dat[3001:7398-l,])

yhat_svm <- predict(fit_svm, newdata = dat[3001:7398-l,])

yhat_glmboost <- predict(fit_glmboost, newdata = dat[3001:7398-l,])

yhat_lm <- predict(fit_lm, newdata = dat[3001:7398-l,])
```

```{r}
# ensembles
ensembles <- data.frame(rf = yhat_rf,
                        svm = yhat_svm,
                        glmboost = yhat_glmboost,
                        lm = yhat_lm)
```

```{r}
corrplot(cor(ensembles), method = "number", type = "upper",na.label.col = TRUE)
```

```{r}
ensembles <- ensembles %>% mutate(combine = (rf + glmboost)/2) %>%
  mutate(combine = ifelse(combine <= 0|combine == Inf, 7, combine))
```


```{r}
hist(yhat_lm, binwidth = 20)
```

```{r}
RMSE <- function(predicted_revenue, true_revenue){
  sqrt(mean((true_revenue- predicted_revenue)^2))
}
```


```{r}
RMSE(ensembles$combine, log10(test_y))
```

```{r}
rsquared <- function (x, y) cor(x, y) ^ 2

rsquared(ensembles$combine, log10(test_y))
```

```{r}
data.frame(predict = ensembles$combine, true_revenue = log10(test_y)) %>%
  ggplot(aes(true_revenue, predict)) +
  geom_point(color = "steel blue", alpha = 0.5) +
  geom_smooth()
```


```{r}
# write csv file for submission

sample_submission$revenue <- 10^ensembles$combine
names(sample_submission) <- c("id","revenue")
write.csv(sample_submission, file = "submission_combine.csv", row.names = F)
```


# **Modeling subset by year**

```{r}
release_years <- levels(factor(df$release_year))
table(df$release_year)
```

```{r}
names(dat)
```

```{r}
summary(
  lm(revenue~.,
     data = filter(dat[1:3000,], release_year < 1960 & release_year >= 1900 ))
)
```

```{r}
dat_test <- dat[3001:7398,] %>%
  mutate(predicted_revenue = ensembles$combine,
         true_revenue = test_y) %>%
  mutate(error = test_y - predicted_revenue)

dat_test %>% ggplot(aes(release_year, error)) +
  geom_point(color = "steel blue")
```

```{r}
years_group <- c(1,2,3)

control <- trainControl(method = "cv",
                        number = 5,
                        p = 0.75)

dat <- dat %>% 
  mutate(yr_group = ifelse(release_year <= 1990,1,
                           #ifelse(release_year > 1960 & release_year <= 1990,2,
                                  ifelse(release_year > 1990 & release_year <= 2010, 2,3)))

#fit_before_1960 <- train(revenue~.,
#                         data = filter(dat[,-c(20,23)],yr_group == 1),
#                         method = "rf",
#                         trControl = control)

fit_60s_90s <- train(revenue~.,
                     data = filter(dat[1:3000,], yr_group == 1),
                     method = "rf",
                     trControl = control)

fit_90s_2k10 <- train(revenue~.,
                     data = filter(dat[1:3000,], yr_group == 2),
                     method = "rf",
                     trControl = control)

fit_after_2k10 <- train(revenue~.,
                     data = filter(dat[1:3000,], yr_group == 3),
                     method = "rf",
                     trControl = control)

yhat <- dat[3001:7398,] %>% 
  mutate(yhat_2 = predict(fit_60s_90s, dat[3001:7398,]),
         yhat_3 = predict(fit_90s_2k10, dat[3001:7398,]),
         yhat_4 = predict(fit_after_2k10,dat[3001:7398,])) %>%
  mutate(final_revenue = ifelse(yr_group == 1, yhat_2,
                                ifelse(yr_group == 2, yhat_3, yhat_4))) %>%
  pull(final_revenue)

RMSE(yhat, log10(test_y))

```

```{r}
data.frame(predict = yhat, true_revenue = log10(test_y)) %>%
  ggplot(aes(true_revenue, predict)) +
  geom_point(color = "steel blue", alpha = 0.5) +
  geom_smooth()
```

```{r}
# write csv file for submission

sample_submission$revenue <- 10^yhat
names(sample_submission) <- c("id","revenue")
write.csv(sample_submission, file = "submission_combine.csv", row.names = F)
```


## **Validation**

## **Discussion**

# **Conclusion**



# **Reference**

