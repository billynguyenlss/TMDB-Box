---
title: "TMDB Box revenue prediction"
author: "Nguyen Bao Long"
date: "8/19/2019"
output:
  pdf_document:
    df_print: kable
    fig_caption: yes
    highlight: tango
    number_sections: yes
    toc: yes
    toc_depth: 3
  word_document:
    toc: yes
    toc_depth: '3'
  html_document:
    df_print: paged
    toc: yes
---

\newpage

```{r setup, include=FALSE}
# set up environment, standardize figure output
options(tinytex.verbose = TRUE)
knitr::opts_chunk$set(echo = TRUE, fig.height = 3.5, fig.width = 5,
                      fig.align = "center")
```

```{r, include=FALSE}
if(!require(matrixStats)) install.packages("matrixStats", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)
if(!require(Amelia)) install.packages("Amelia", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)
if(!require(gridExtra)) install.packages("gridExtra", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)
if(!require(tidyverse)) install.packages("tidyverse", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)
if(!require(caret)) install.packages("caret", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)
if(!require(kableExtra)) install.packages("kableExtra", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)
if(!require(TMDb)) install.packages("TMDb", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)
if(!require(GGally)) install.packages("GGally", 
                   repos = "http://cran.us.r-project.org", 
                   dependencies = TRUE)
```


```{r import library, include=FALSE}
library(tidyverse)
library(caret)
library(matrixStats)
library(grDevices)
library(gridExtra)
library(Amelia)
library(DataExplorer)
library(knitr)
library(kableExtra)
library(lubridate)
library(corrplot)
library(TMDb)
library(GGally)
```


\newpage

**Abstract** This document belongs to the second project - Choose Your Own of the course HarvardX: PH125.9x Data Science: Capstone project. Inspired by the difficulty and challenging in Kaggle's competitions, and my expectation to practice as much as possible data science techniques I have learned in the HarvardX - Data Science program, in this project I used the dataset from Kaggle TMDb Box Office Competition, where competitors were presented with metadata on over 7,000 past films from The Movie Database (TMDb) to predict their overall worldwide box office revenue. Furthermore, this competition allowed competitors to use additional publicly dataset for modeling, therefore it's good opportunity to practice the web scrapping techniques. 

This documents consist 4 sections: section (i) describe the project background, project objective, design of experiment; section (ii) describe data wrangling process, missing data transformation, outlier detection, web scrapping, data visualization, main package using are dplyr, stringr, rvest, ggplot2, ggExtra; section (iii) describe the process of data exploratory analysis to study the effect and relationship of budget, popularity, production companies, genres, movies belongs to a collection to revenue; section (iv) describe the process to build up a machine learning model to predict revenue and compare different machine learning methods includes random forest, support vector machine, gradient boosting machine, bayesian generalized linear model and linear model, main package using in this section is caret; section (v) describe the final results and further discussion.

This document describe my solution include data preparation, data wrangling, data visualization, model development and its performance evaluation. The main R packages used in this project were tidyverse for data wrangling, knitr & kableExtra and ggplot2 & gridExtra for data visualization, revest, TMDb for web scraping, caret for modeling and modeling performance evaluation.

# **Introduction**

## **Background**

### **TMDB Box Office Competition**

*"Can you predict a movie's worldwide box office revenue?"*

On February $9^{th}, 2019$ Kaggle launch a competition, using the TMDB Box Office dataset to predict a movie's worldwide box office revenue. This competition was end by May $31^{th}$, 2019 which total 1398 teams, 1618 competitors and 19,034 entries. Here come the introduction from Kaggle:

"In a worldâ€¦ where movies made an estimated $41.7 billion in 2018, the film industry is more popular than ever. But what movies make the most money at the box office? How much does a director matter? Or the budget? For some movies, it's "You had me at 'Hello.'" For others, the trailer falls short of expectations and you think "What we have here is a failure to communicate."

In this competition, you're presented with metadata on over 7,000 past films from The Movie Database to try and predict their overall worldwide box office revenue. Data points provided include cast, crew, plot keywords, budget, posters, release dates, languages, production companies, and countries. You can collect other publicly available data to use in your model predictions, but in the spirit of this competition, use only data that would have been available before a movie's release."

### **Competition evaluation**

To evaluate results in Kaggle's competition, competitors must develop machine learning model to predict the international box office revenue for each movie. For each id in the test set, competitors must predict the value of the revenue variable. 

Submissions are evaluated on Root-Mean-Squared-Logarithmic-Error (RMSLE) between the predicted value and the actual revenue. Logs are taken to not overweight blockbuster revenue movies.

Since this competition completed on May $31^{st}$, following is the final public leaderboard.

```{r, fig.width=8, include=FALSE}
# import leaderboard data
url_leaderboard <- url("https://raw.githubusercontent.com/billynguyenlss/TMDB-Box/master/data/tmdb-publicleaderboard.csv")
tmdb_leaderboard <- read.csv(url_leaderboard, na.strings=c("", '#N/A', '[]', '0'))
tmdb_leaderboard$SubmissionDate <- ymd_hms(tmdb_leaderboard$SubmissionDate)
```

```{r, include=FALSE}
final_board <- tmdb_leaderboard %>% group_by(TeamName) %>%
  summarize(submitted_times = n(),
            best_score = min(Score)) %>% arrange(best_score)
```

```{r, include=FALSE}
top_10 <- final_board[140,3]
```

```{r, fig.width=8}
final_board %>% 
  ggplot(aes(best_score)) +
  geom_histogram(fill = "steel blue", binwidth = 0.1) +
  scale_x_continuous(minor_breaks = seq(0, 30, 1)) +
  geom_vline(xintercept = 1.7068, color = "red") +
  geom_text(aes(x = 5, y = 240, label = "top 10% (RMSLE < 1.7068)"), color = "red") +
  labs(title = "TMDB Box office competition final leaderboard",
       caption = "Data source from Kaggle's TMDB Box office competition public leaderboard")
```

**Noted:** another point that unfortunetely, even Kaggle's competition rules mentioned *"use only data that would have been available before a movie's release"*, but I found that many competitors used the vote count and vote average in their model, which should be available after the movie's release. Therefore in this project, I did not submit the results to the competition's leaderboard for a benchmarking.

## **Project objective**

My objective are:

1) To practice data exploratory analysis techniques which I have learned in this course:
  * Text mining using `stringr`, 
  * Data visualization using `ggplot2`, `gridExtra`, `knitr`, `kableExtra`,
  * Summarize and transform data using `dplyr`, 
  * Web scrapping using `rvest`,
  * Machine learning modeling using `caret`.
  
2) To develop a machine learning model to predict the internaltion box office revenue and reduce RMSLE as much as possible.

3) To improve my business writing and data science reporting skills, using R and `rmarkdown`.

## **Project methodology**

This project has 4 high-level steps:

+ Step 1 **data overview and pre-processing**: overviewing variables, type of data, NA percentage, quality of data... querying, cleaning using additional data and selecting variables.

+ Step 2:**data exploratory analysis and features engineering**  exploring and visualizing the data to have an overview on the effect and correlation with-in and/or between the variables and the output (revenue). Based on what's insights gained after analysis, the new potential features will be able to add in the predicting model to improve modeling performance.

+ Step 3: **modeling and performance evaluation**. This section describe the modeling development process, comparing different machine learning method and selecting the best method for final modeling. The metric to evaluate model performance is RMSLE (Root Mean Squared Logarithmic Error) which is same standard with the Kaggle Movies Box Office competition. The RMSLE are calculated by following formula:

\begin{center}

$RMSLE = \sqrt{\frac{\sum_{i = 1}^{n} (ln y_{i} - ln \hat{y}_{i})^{2}}{n}}$

\end{center}

With:

 * $y_{i}$ the true revenue of movie i
 
 * $\hat{y}_{i}$ the predicted revenue of movie i

```{r}
# write function RMSLE to evaluate modeling performance
RMSLE <- function(predicted_revenue, true_revenue){
  sqrt(mean((logb(true_revenue)- logb(predicted_revenue))^2))
}
```

```{r}
# write function RMSL to evaluate modeling performance
RMSE <- function(predicted_revenue, true_revenue){
  sqrt(mean((true_revenue- predicted_revenue)^2))
}
```

* Step 4: **validation on the test set**. This section describe the peformance of the final model from previous step, using the test dataset. The true revenue for this step is received from the additional TMDB data. The metric to evaluate final performance was RMLSE as well.

# **Data overview and pre-processing**

## **Kaggle competition's dataset**

The dataset used in this competition has been collected from the Movies Database (https://www.themoviedb.org/). The movie details, credits and keywords have been collected from the TMDB Open API. This competition uses the TMDB API but is not endorsed or certified by TMDB. Their API also provides access to data on many additional movies, actors and actresses, crew members, and TV shows.

This data contain 7398 movies and a variety of metadata. Movies are labeled with id. Data points include cast, crew, plot keywords, budget, posters, release dates, languages, production companies, and countries. The dataset was subset to 2 dataset, the `train.csv` has 3000 movies and `test.csv` with 4398 movies.

All datas which were used in this project, are able to download from my github repo.

**Import data**

```{r}
# download raw data from my github repo
url_train <- 
  url("https://raw.githubusercontent.com/billynguyenlss/TMDB-Box/master/data/train.csv")
train_set <- read.csv(url_train, na.strings=c("", '#N/A', '[]', '0'))

url_test <- 
  url("https://raw.githubusercontent.com/billynguyenlss/TMDB-Box/master/data/test.csv")
test_set <- read.csv(url_test, na.strings=c("", '#N/A', '[]', '0'))

url_sample_submission <- 
  url("https://raw.githubusercontent.com/billynguyenlss/TMDB-Box/master/data/sample_submission.csv")
sample_submission <- read.csv(url_sample_submission, na.strings=c("", '#N/A', '[]', '0'))
```

**Data overview**

The **train_set** have 3000 observations of 23 variables.

```{r}
dim(train_set)
```

The **test_set** has 4398 observations of 22 variables.

```{r}
dim(test_set)
```

Combine train and test dataset to one data to save time for data preprocessing and transformation.

```{r combine train test data, warning=FALSE}
# combine train_set and test_set to reduce time to pre-processing data
train_set <- train_set %>% mutate_if(is.factor, as.character)
test_set <- test_set %>% mutate_if(is.factor, as.character)
df <- bind_rows(train_set, test_set)
```

Lets take a glimpse at Kaggle's dataset to get a feel of how it looks like.

```{r}
glimpse(df)
```

 We could see the first problem of the data, text structure of character variables such as belong to collection, genres, crew, cast... is really complicated. For example in the first value of genres "[{'id': 35, 'name': '$\color{red}{\text{Comedy}}$'}]", , only "Comedy" is informative.
 
 The numeric variables are budget, revenue, popularity, runtime. On the first look, the minimum budget and minimum revenue are 1, which create concern on the data accuracy. Also there are 812 NA values in budget, approximate
 `r 100*round(812/3000,3)`
 % on total observation.

```{r, include=FALSE}
# creat summary table on numeric variables
#data.frame(do.call(cbind, lapply(train_set[,c(1,3,10,15,23)], summary))) %>%
#  kable() %>%
#  kable_styling(latex_options = c("HOLD_position","scale_down"), 
#                position = "center", font_size = 10, full_width = F,
#                bootstrap_options = c("striped", "hover"))
```

The summary table on variables:

Variables               Type         Description       
----------------------  ------------ ---------------------------------------------------------------
budget                  integer      Budget of a movie in American Dollar (USD) and not be adjusted 
                                     for inflation. 
popularity              numeric      Popularity was based on user interactions on the TMDb website
runtime                 integer      Duration in minutes of a movie
revenue                 integer      Revenue of a movie in American Dollar (USD) and not be adjusted
                                     for inflation. Recommended resources for box office revenue 
                                     information: Box Office Mojo and The Numbers.
release_date            date / time  Release date of a movie 
original_language       character    The original language of a movie
original_title          character    The original title is usually the title of the original version 
                                     of the film when it is first officially released locally.
overview                character    Overviews should describe the plot of the movie. They should be 
                                     to the point, spoiler-free and brief. A few lines at most.
poster_path             character    link to movie's pÃ³ter   
production_companies    character    list of production companies
production_countries    character    list of production countries
spoken_languages        character    Only the languages spoken in the original version. No 
                                     translated/dubbed languages.
tagline                 character    A movie tagline is usually a short promotional text used on 
                                     the poster.
Keywords                character    to describe the plot of movie. Around 5-10 keywords for TV 
                                     zshows and 15-20 keywords maximum for movies is reasonable.
cast                    character    Only the cast of the original (not dubbed or extended) version.
crew                    character    Only the crew credited in the original version.
----------------------  ------------ ---------------------------------------------------------------

More description on variables could be reference from following link 

https://www.themoviedb.org/bible/movie/

**NA value status**

Missing values must be dropped or replaced in order to draw correct conclusion from the data. The second problem of this dataset is missing value in many variables.

```{r, fig.height=5}
plot_missing(df)
```

Two highest NA ratio variables are`belongs_to_collection` and  `homepage`, which are more than 60%.
`budget`, which suppose the most important variables, also have 27.07% NA values.
Other `tagline`, `Keywords`, `production_companies` have lower NA value ratio, less than 20%.

## **Additional dataset**

The third problem is that there were many concern on the quality of dataset provided in this Kaggle competition, especially the accuracy of budget, revenue, popularity...  (reference: https://www.kaggle.com/c/tmdb-box-office-prediction/discussion)  
Furthermore, this competition allowed to use publicly available data, therefore I used additional dataset from following data sources:

  + the Movies Database (https://www.themoviedb.org/)

  + Kaggle kernels with high score 

  + Wikipedia (https://www.wikipedia.org/)

Those data use to correct the budget, revenue, popularity, release date... as well as use as new additional variables for modeling.

### **The Movies Database API**

The additional data from TMDB website (https://www.themoviedb.org/?language=en-US) is openned and able to download by following their instruction.

The instruction to retrieve data from TMDb website is reference from following link (http://www.planetanalytics.in/2017/05/how-to-extract-movie-data-from-movie.html).

The TMDb packages was also available in R libraries (https://cran.r-project.org/web/packages/TMDb/index.html) which you can retrieve other features for this competition. 

**Import data**

Due to very long processing time to download data from TMDb website, I did not include the code in this report, but you can follow the instruction from previous sections or download data direct from my github repo.

```{r}
# download additional data from my github repo
url_additional <- url("https://raw.githubusercontent.com/billynguyenlss/TMDB-Box/master/data/personal%20additional%20data/full_additional_features_2.csv")
additional_data <- read.csv(url_additional, na.strings=c("", '#N/A', '[]', '0'))
```

**Data overview**

This data set have 7398 observations of 14 variables. The `vote_count` and `vote_average` were included but there were available after the movie had been released.

```{r}
glimpse(additional_data)
```

Summary table of additional data

Variables               Type         Description       
----------------------  ------------ ---------------------------------------------------------------
imdb_id                 character    identified number in imdb system, extract from Kaggle's dataset
new_budget              integer      the budget number downloaded from TMDb
vote_count              integer      the number of vote given by users after movie was released
vote_average            double       the average vote given by users after movie was released
new_popularity          double       the popularity number downloaded from TMDb
new_revenue             integer      the revenue downloaded from TMDb
new_runtime             integer      runtime number downloaded from TMDb
new_release_date        date/time    release date downloaded from TMDb
genres1                 character    first genre of a movie
genres2                 character    second genre of a movie
genres3                 character    third genre of a movie
company1                character    first company of a movie
company2                character    second company of a movie
company3                character    third company of a movie
----------------------  ------------ ---------------------------------------------------------------

Instead of submit to Kaggle's leaderboard, I extract test's revenue from additional data to a vector named `test_y` for final modeling performance evaluation.

```{r, warning=FALSE}
# extract the true_rating value from additional data
test_y <- test_set %>% left_join(additional_data, by = "imdb_id") %>%
  mutate(new_revenue = ifelse(is.na(new_revenue), median(new_revenue, na.rm = T), new_revenue)) %>%
  pull(new_revenue)

summary(test_y)
```


### **High score Kaggle kernal**

Below are some kernel which inspired me to complete my report, as well as a good source for reference.

  * Zero92's kernel (Python language)
  
  (RMSLE = 1.6998) https://www.kaggle.com/zero92/tmdb-prediction
  
  * tavoosi's kernel (R language)
  
  (RMSLE = 1.95841) https://www.kaggle.com/tavoosi/predicting-box-office-revenue-with-random-forest
  
**Data import**

```{r}
# import Kaggle additional data
#kaggle_budget <- read.csv("kernel_budget.csv")
#kaggle_revenue <- read.csv("kernel_revenue.csv")
```

**Data overview**

There are 126 observation on kaggle_budget data and 4 observation on kaggle_revenue data.

```{r}
# take a look on kaggle budget
#glimpse(kaggle_budget)
```

```{r}
# take a look on kaggle revenue
#glimpse(kaggle_revenue)
```

### **Wikipedia**

The second additional data was scrapped from wikipedia, using `rvest` package. 
Because of long processing time to scrapping and pre-processing, I copied but not allowed the scrapping code running in my report. You can refer to the scrapping code in Appendix section or download the completed data from my github repo. The code to download and import the additional data was as following:

**Import data**

```{r}
# download data from my github repo
url_wikipedia_budget <- 
  url("https://raw.githubusercontent.com/billynguyenlss/TMDB-Box/master/wikipedia_us_budget.csv")

wikipedia_budget <- read.csv(url_wikipedia_budget, na.strings=c("", '#N/A', '[]', '0'))

# to assure the final budget as numeric type
wikipedia_budget$final_budget <- as.numeric(wikipedia_budget$final_budget)

# check if any NA value in the additional budget data
mean(is.na(wikipedia_budget$final_budget))
```

**Overview data**

```{r}
glimpse(wikipedia_budget)
```

Summary table of variables:


Variables               Type         Description       
----------------------  ------------ ---------------------------------------------------------------
imdb_id                 character    the identified number in imdb system
wiki_budget             character    the original scrapping from wikipedia
new_budget              integer      extracted number from wiki_budget (unit probably single, 
                                     thousand, million usd/jpy/cad/...)
currency_unit           integer      currency exchange number from other currency to usd
final_budget            double       final budget after transforming to usd
----------------------  ------------ ---------------------------------------------------------------

**In summary**, top 3 problems were recognized in this section include:

  (i) missing/NA values, 
  
  (ii) complicated text structure, 
  
  (iii) inaccuracy data. 
  
In next section, each variable was explored and transformed to informative variables.  

## **Data pre-processing**

### **Release date**

The current class of release_date was "chr" (character), so we firstly convert it to type "date and time".

```{r}
df$release_date <- mdy(df$release_date)
summary(df$release_date)
```

The time frame was really wide, the soonest released date was 1969-01-01 and the latest is "2068-12-30".

The latest release_date "2068-12-30" was impossible. There were total
`r df %>% filter(release_date >= mdy("8-27-2019")) %>% nrow`
days later than the time I was doing this report on August $27^{th}$, 2019.
We also havd 1 NA value in the `release_date`. 

To correct the `release_date` and replace NA value, I used the release date in TMDb additional data set. Now we merged the addition data to the `df` dataset.

```{r, warning=FALSE}
# left joining the addition data into df
df <- df %>% left_join(additional_data, by = "imdb_id")
df$new_release_date <- as.character(df$new_release_date)

df$release_date <- df$new_release_date
df$release_date <- mdy(df$release_date)
```

## **Revenue**

```{r}
summary(train_set$revenue)
```

The minimum revenue is 1 and maximum revenue is `r max(train_set$revenue)`. There are total
`r sum(train_set$revenue < 1000)` movies have revenue value less than 1000. This is due to those movies have currency measure by million USD instead of single USD.

To correct in case the revenue is wrong or not up-to-date, I used the new_revenue from TMDB additional data instead of original revenue from Kaggle data.

```{r}
df <- df %>%
  mutate(new_revenue = ifelse(is.na(new_revenue), revenue, new_revenue))

df$revenue[1:3000] <- df$new_revenue[1:3000]
```

Second step to correct the revenue, I replace revenue by the value from Kaggle kernel's data.

```{r}
# rename the id variable
df <- df %>% rename(id = Ã¯..id)

# update new_revenue
#for (i in kaggle_revenue$id){
#  df$new_revenue[i] == kaggle_revenue$kernel_revenue[which(kaggle_revenue$id == i)]
#}
```

## **Budget**

Budget seem to be the most important variables to predict revenue of a movie.

```{r}
summary(df$budget)
```

Similar to revenue, minimum budget is 1, while average budget is 25,961,487 and maximum budget is 380,000,000 USD. The same problem due to different currency measure of movies (million USD vs single USD).

```{r}
train_set %>% select(budget, revenue) %>%
  mutate(budget_status = ifelse(is.na(budget), "missing budget",
                                ifelse(budget <=1000,"low budget","normal budget")),
         revenue_status = ifelse(revenue <= 1000,"low revenue","normal revenue")) %>%
  group_by(budget_status, revenue_status) %>%
  summarize(count = n(),
            percent = 100*round(n()/nrow(train_set),3)) %>%
  mutate(remarks = ifelse(count == 5,"wrong budget",
                   ifelse(count == 34, "NA impact",
                   ifelse(count == 778, "NA impact",
                   ifelse(count == 10, "wrong revenue","-"))))) %>%
  kable(caption = "Summarized table of abnormal budget and revenue") %>%
  kable_styling(latex_options = c("HOLD_position"),
                bootstrap_options = c("striped", "hover"),
                full_width = F, position = "center")
```

Therefore in this project, I used new budget from TMDb additional data instead of Kaggle's data.

**New budget**

To correct the `new_budget`, the first step is to replace missing value and any budget number less than 1000 and its respective revenue greater than 10,000 by `final_budget` from wikipedia data.

```{r}
# joining addition wikipedia budget
df <- df %>% mutate(imdb_id = as.factor(imdb_id)) %>%
  left_join(wikipedia_budget[,c(1,2,5)],by = "imdb_id")


#replace low budget value
df <- df %>% 
  mutate(new_budget = ifelse((new_budget <= 1000 & revenue > 10000), final_budget, new_budget))

# replace NA budget value by wikipedia budget
df <- df %>% mutate(new_budget = ifelse(is.na(new_budget),
                                    final_budget, new_budget))

mean(is.na(df$new_budget))
```

The NA value was reduced from 27.07% to 1.03%. Because the wikipedia budget number was not available for every movies in our dataset, therefore to replace remain missing value, I used the median budget by release year.

```{r}
# create summary budget table by release year
df$release_year <- year(df$release_date)

budget_by_year <- df %>%
  group_by(release_year) %>%
  summarize(avg_budget = mean(new_budget, na.rm = T),
            median_budget = median(new_budget, na.rm = T))

# replace NA budget by median_budget value
df <- df %>% left_join(budget_by_year, by = "release_year") %>%
  mutate(new_budget = ifelse(is.na(new_budget), median_budget,
                         new_budget))
df$new_budget[is.na(df$new_budget)] <- df$median_budget

# re-check NA value in budget
mean(is.na(df$new_budget))
```

The last step is to replace the budget value with the budget number from Kaggle high score's kernel.

```{r}
# update new_budget
#for (i in kaggle_budget$id){
#  df$new_budget[i] == kaggle_budget$kernel_budget[which(kaggle_budget$id == i)]
#}
```

**Original budget**

```{r}
#replace low budget value
df <- df %>% 
  mutate(budget = ifelse((budget <= 1000 & revenue > 10000), final_budget, budget))

# replace NA budget value by wikipedia budget
df <- df %>% mutate(budget = ifelse(is.na(budget),
                                    final_budget, budget))

mean(is.na(df$budget))
```

```{r}
# replace NA budget by median_budget value
df$budget[is.na(df$budget)] <- median(df$budget, na.rm = T)

# re-check NA value in budget
mean(is.na(df$new_budget))
```

### **Runtime**

The missing values in `runtime` was to be replaced by median run time value.

```{r}
df$runtime[is.na(df$runtime)] <- median(df$runtime, na.rm = T)
```

Now we can take the first look on the corrected value of budget, revenue, popularity and runtime.

```{r, fig.width=8, fig.height=3, warning=FALSE}
df %>% select(new_revenue, new_budget, new_popularity, new_runtime) %>%
  gather(1:4, key = "variables", value = "value") %>%
  ggplot(aes(value, fill = variables)) +
  geom_histogram(color = "white") + facet_wrap(.~variables, scales = "free", ncol = 4) +
  theme(legend.position = "none")
```

```{r, include=FALSE}
average_revenue <- mean(df$new_revenue, na.rm = TRUE)
```

Not many movies have high revenue.
`r 100*round(mean(train_set$revenue <= average_revenue),3)`
% movies in the training dataset have revenue lower than the average revenue. Only
`r 100 - 100*round(mean(train_set$revenue <= average_revenue),3)`
% movies have revenue greater than the average revenue.

### **ROI**

Return on investment is a ratio between net profit and cost of investment. A high ROI means the investment's gains compare favorably to its cost. As a performance measure, ROI is used to evaluate the efficiency of an investment or to compare the efficiencies of several different investments.

```{r}
df %>% mutate(ROI = (revenue - budget)/budget) %>%
  select(title, budget, revenue, ROI, vote_count, vote_average, popularity) %>%
  arrange(desc(ROI)) %>% head(10) %>%
  kable(caption = "Top movies with greatest ROI", digits = 2) %>%
  kable_styling(latex_options = c("HOLD_position","scale_down"), 
                position = "center", font_size = 10,
                bootstrap_options = c("striped", "hover"))
```

The most profitable movie is "Paranormal Activity" (ROI 12889), which is a 2007 American supernatural horror film co-produced, written, directed, photographed and edited by Oren Peli. It centers on a young couple (Katie Featherston and Micah Sloat) who are haunted by a supernatural presence in their home. The film earned nearly $108 million at the U.S. box office and a further $85 million internationally for a worldwide total of $193 million (reference: https://en.wikipedia.org/wiki/Paranormal_Activity).

```{r}
which(df$title == "Paranormal Activity")
```

The second most profitable movie is "The Blair Witch Project". Reference from wikipedia, The Blair Witch Project grossed nearly $250 million worldwide on a modest budget of $60,000, making it one of the most successful independent films of all time (reference: https://en.wikipedia.org/wiki/The_Blair_Witch_Project).

```{r}
which(df$title == "The Blair Witch Project")
```

Both of most profitable movies should consider as outlier to our model. To remove out the outliers, I created a vector names outlier_rows to contain the outlier row number.

```{r}
outlier_rows <- c(1231,1680)
```


### **Change across time**

```{r}
summary(df$release_date)
```

The soonest release date was "1915-02-08" and the latest release date was "2017-08-11", the period of time were 97 years. Please be noticed that many events happened in the world during this time, world war II, economic crisis, technology change, movie's audience interest... could impacted direct to the currency, exchange rate and indirect to movies box office industry.

```{r, fig.width=8, fig.height=4}
# calculate the release month
df$release_month <- month(df$release_date)
df$weekday <- weekdays(df$release_date)

# visualize the different number of movies by release year and release month
grid.arrange(
  df %>% 
    ggplot(aes(release_year)) +
    geom_bar(fill = "steel blue") +
    labs(title = "Number of movies by release year"),
  
  df %>% ggplot(aes(release_month)) +
    geom_bar(fill = "steel blue", color = "white") +
    labs(title = "Number of movies by release month"),
  
  df %>% group_by(weekday) %>% summarize(count = n()) %>%
    mutate(weekday = reorder(weekday, count)) %>%
    ggplot(aes(weekday, count)) +
    geom_col(fill = "steel blue", color = "white") +
    labs(title = "Number of movies by weekday"),
  
  ncol = 2
)
```

The movies box office industry growth slowly before decade 1980s , after this time it's continuous growing every year. We could see
25% movies released in total
`r 1993 - 1921`
years from 1921 to 1993, but the next 25% movies released in only
`r 2001 - 1993`
years from 1993 to 2001.
50% remain movies released in 
`r 2018 - 2001`
after 2001.

`r round(mean(df$weekday == "Friday"),3)*100` movies released on Friday,
`r round(mean(df$weekday == "Thursday"),3)*100` movies released on Thursday,
`r round(mean(df$weekday == "Wednesday"),3)*100` movies released on Wednesday,
remain movies released on other weekdays.

### **belongs_to_collection**

This variable have greatest number of NA values. There are `r 100*round(mean(is.na(df$belongs_to_collection)),4)`
% NA values and 
`r 100*round(mean(!is.na(df$belongs_to_collection)),4)`
% not-NA values. The NA values represented for a movie not belongs to any collection.

For any movie belong to a collection, following was the text structure:

[{'id': 313576, 'name': '$\color{red}{\text{Hot Tub Time Machine Collection}}$', 'poster_path': '/iEhb00TGPucF0b4joM1ieyY026U.jpg', 'backdrop_path': '/noeTVcgpBiD48fDjFVic1Vz7ope.jpg'}]

Not all strings were necessary, only the name of the collection ($\color{red}{\text{red text}}$) is informative. 

The collection's name was extracted by following code:

```{r}
# extract collection
df$collection <- str_extract(df$belongs_to_collection, 
            pattern = "(?<=name\\'\\:\\s{1}\\').+(?=\\'\\,\\s{1}\\'poster)")
df$collection[is.na(df$collection)] <- "no collection"
```

There were total
`r length(levels(factor(df$collection)))`
collection from both train_set and test_set.
To visualize the difference between movies belong to a collection and movies not belong to any collection, I added one new feature `collection_status` to classify a movie belong to a collection or not. The following code and figure represented for this difference.

```{r, fig.width=7, fig.height=3.5}
df <- df %>% mutate(collection_status = ifelse(collection == "no collection", 0, 1))
grid.arrange(
df %>% mutate(collection_status = factor(collection_status)) %>%
  ggplot(aes(x = collection_status, fill = collection_status)) +
  geom_bar() +
  theme_classic() +
  theme(legend.position = "none")+
  scale_fill_manual(values = c("grey","steel blue")) +
  labs(title = "frequency by collection status",
       caption = " 
       "),
  
df %>% mutate(collection_status = factor(collection_status)) %>%
  ggplot(aes(x = collection_status, revenue, fill = collection_status)) +
  geom_boxplot() +
  theme_classic() +
  theme(legend.position = "none") +
  scale_fill_manual(values = c("grey","steel blue")) +
  labs(title = "boxplot of collection status",
       caption = "0 - not belong to any collection,
        1 - belongs to collection"),
ncol = 2)
```

In average, a movie belongs to a collection has higher median revenue than other movies not belong to any collection. 

###  **genres**

Let's take a look on the genres. 

```{r}
head(df$genres,2)
```

A movie can have one genre or multiple genres. Each genre represents by following text *"{'id': 35, 'name': '$\color{red}{\text{Comedy}}$'}"* and separate by comma. Only the $\color{red}{\text{red text}}$ is informative.

There was also
`r sum(is.na(df$genres))` 
NA value. I replaced those NA values by "no genre".

```{r}
# replace NA value by "no genre"
df$genres[is.na(df$genres)] <- "no genre"
```

Suppose the first genre from the genres strings was the main genre for each movie. Therefore I extracted the first genre in genres and add them to a new variable named `main_genre`.

```{r}
# create a vector with all genre levels
genres_matching_point <- "Comedy|Horror|Action|Drama|Documentary|Science Fiction|
              Crime|Fantasy|Thriller|Animation|Adventure|Mystery|War|Romance|Music|
              Family|Western|History|TV Movie|Foreign"

# extract the main genre from genres

df$main_genre <- str_extract(df$genres, genres_matching_point)
df$main_genre[is.na(df$main_genre)] <- "no genre"
```

Now figure out the difference of each main genre, by the number of movies and revenue.

```{r, fig.width=8, fig.height=3.5}
grid.arrange(
  
# barplot number of movies per genre  
df %>% 
  group_by(main_genre) %>%
  summarize(count = n()) %>%
  mutate(main_genre = reorder(main_genre, count),     
         top_genre = ifelse(main_genre %in% c("Drama","Comedy","Action"),
                            "top count",
                            ifelse(main_genre %in% c("Adventure","Animation",
                            "Science Fiction"),"top revenue","common"))) %>%
  ggplot(aes(main_genre, count, fill = top_genre)) +
  geom_col() +
  scale_fill_manual(values = c("grey","steel blue","#FF9900"))+
  theme_classic() +
  coord_flip()+
  labs(title = "counting number of first genre") +
  theme(legend.position = "none"),

# barplot average revenue per genre
df %>% 
  group_by(main_genre) %>%
  summarize(avg_revenue = mean(revenue, na.rm = TRUE)) %>%
  mutate(main_genre = reorder(main_genre, avg_revenue),
         top_genre = ifelse(main_genre %in% c("Drama","Comedy","Action"),
                            "top count",
                            ifelse(main_genre %in% c("Adventure","Animation",
                            "Science Fiction"),"top revenue","common"))) %>%
  ggplot(aes(main_genre, avg_revenue, fill = top_genre)) +
  geom_col() +
  scale_fill_manual(values = c("grey","steel blue","#FF9900"))+
  theme_classic() +
  coord_flip()+
  labs(title = "average revenue of first genre") +
  theme(legend.position = "none"),
ncol = 2)
```

We could see:

  + Top three common genres with highest number of movies were *Drama, Comedy, Action*.
  + Top three genres with greatest average revenue were *Adventure, Animation, Science Fiction*, and the average revenue of each genre are quite different compared to others.

**Number of genres**

Because a movie could have more than one genre, I created the new variable to visualize the total genres of each movie.

```{r}
df$number_genres <- str_count(df$genres, pattern = "id")
df$number_genres[is.na(df$number_genres)] <- 0
```

Now we evaluate the correlation between budget, revenue on the number of genres.

```{r, fig.width=8, fig.height=3}
grid.arrange(
  df %>% 
    ggplot(aes(number_genres)) +
    geom_bar(fill = "steel blue"),
  
  df %>% group_by(number_genres) %>%
    summarize(avg_budget = mean(budget, na.rm = TRUE)) %>%
    ggplot(aes(number_genres, avg_budget)) +
    geom_col(fill = "steel blue"),
  
    df %>% group_by(number_genres) %>%
    summarize(avg_revenue = mean(revenue, na.rm = TRUE)) %>%
    ggplot(aes(number_genres, avg_revenue)) +
    geom_col(fill = "steel blue"),
  
  ncol = 3
)
```

We could see:

  + Almost movies have two or three genres. 
  + In average, movies which number of genres were from 3 to 6 seem to have higher average revenue compared to other movies which less than 3 genres or greater than 6 genres.

### **production_companies**

From previous section, we known there were total  
`r sum(is.na(df$production_companies))`
NA values, approximate
`r 100*round(mean(is.na(df$production_companies)),4)`
% of total observation. Let's take a quick look on the top rows of this variable.

```{r}
head(df$production_companies, 3)
```

A movie could has single or more than one production company. Each production company represent by a name (string), and its id (number), for example {'name': '$\color{red}{\text{Paramount Pictures}}$', 'id': 4}.
I kept only the $\color{red}{\text{red text}}$ and removed other characters due to it had no meaning for my analysis.

To explore the effect of production companies on the revenue, I create three following variables:

  1) `number_of_company`: represents for the number of production companies of a movie.
  
  2) `company_experience`: represents for the number of experience year of a production company, from the first release date to the latest release date.
  
  3) `company_ranking`: represents for company ranking, calculate by the average number of movies per year of a company. As we know some big movie production company could release more than 5 movies a year.
  
Also to evaluate different production company, I created a summary data group by each production company. Suppose the first company in the production companies list of each movie would be the leading company whom had biggest effect on the success of those movie, I extracted the first company to created this summary data. Following were the metrics to evaluate performance of a production company:

  + *number of release movies*, represent for the experience of a production company, to order a production company by its size.

  + *percent*  by number of release movies, represent for the size of production company in the movie market, to order a production company by its size.

  + *average budget per company*, represent for the financial power of production company.

  + *average revenue per company*, represent for its average revenue.

  + *revenue percent*, represent for the percent of total revenue of production company compare to other companies, to order a production company by its successful levels.

  + *ROI per company*, represent for the average Return on Investment of a production company, to order a production company by its effectiveness.

All new features were calculated as following:

**Number of production companies**

To calculate number of production companies per movie, I simply count the text `'name'`. For any movies missing the production companies information, I replaced by the median value.

```{r}
# calculate number of company of a movie
df$number_of_company <- str_count(df$production_companies, pattern = "\\'name\\'")

# replace NA number by median
df$number_of_company[is.na(df$number_of_company)] <- median(df$number_of_company, na.rm = TRUE)
```

Figure out the number of production company per movie and how it correlated to the revenue.

```{r,fig.height=3, fig.width=8}
# figure out the number of company per movies and revenue change
grid.arrange(
  df %>% mutate(number_of_company = factor(number_of_company)) %>%
    ggplot(aes(number_of_company)) +
    geom_bar(fill = "steel blue", color = "white") +
    labs(title = "number of production company"),
  
df %>% 
  ggplot(aes(number_of_company, revenue)) +
  geom_point(color = "steel blue", alpha = 0.7) +
  labs(title = "revenue by number of production company"),

ncol = 2)
```


`r 100*round(mean(df$number_of_company <=5),3)`
% movies have less than or equal 5 production companies. The revenue seem to decrease when the number of production company greater than 5.

**Production companies**

Before calculate other variables, I replaced all unnecessary characters and kept only the production company's name in a new variables named `companies`.

```{r}
# remove all unnecessary character and keep only production company's name
df$companies <- gsub("(\\[?\\{\\'name\\'\\:\\s\\')|(\\'\\,\\s{1}\\'id\\'\\:\\s{1}\\d+\\}\\]?)",
                     "",df$production_companies)

# replace NA value in feature companies by "no production companies info"
df$companies[is.na(df$companies)] <- "no production companies info"

# create a list of all production companies
production_companies <- strsplit(df$companies, ", ") 
production_companies <- unlist(production_companies, use.names=FALSE)
```

Extract the first company and store into variables named `first_company`.

```{r}
# extract first company
df$first_company <- gsub("\\,\\s{1}.*","",df$companies)
```

The summary data of production companies was created by following code: 

```{r}
# calculate the total revenue from train data
total_revenue <- sum(train_set$revenue)

# create a summary table by first company
first_company_summary <- df[] %>% group_by(first_company) %>%
  summarize(movies_per_company = n(),
            percent = 100*round(n()/nrow(df),3),
            avg_budget_per_company = mean(budget, na.rm = TRUE),
            avg_revenue_per_company = mean(revenue, na.rm = TRUE),
            revenue_percent = round(100*sum(revenue, na.rm = TRUE)/total_revenue,0),
            ROI_per_company = round((mean(revenue, na.rm = TRUE) - 
                           mean(budget, na.rm = TRUE))/
                     mean(budget, na.rm = TRUE),3),
            company_experience = max(release_year) - min(release_year) + 1) %>%
  mutate(company_ranking = movies_per_company/company_experience) %>%
  mutate(company_ranking = ifelse(first_company == "no production companies info",
                                  1,company_ranking))
```

```{r, fig.width=8, fig.height=5}
first_company_summary %>% arrange(desc(company_ranking)) %>%
  head(10) %>%
  kable(caption = "Top 10 production companies") %>%
  kable_styling(latex_options = c("HOLD_position","scale_down"), 
                position = "center", font_size = 10,
                bootstrap_options = c("striped", "hover"))
```


**Insight** 

Although there were total 3000 movies in train data set and 
`r length(levels(factor(df$first_company[1:3000])))`
production companies in variables first company, but:

* Top 10 companies appeared as the first company in 
`r 167 + 158 + 122 + 90 + 70 + 69 + 62 + 44 + 44`
movies, approximate
`r round((167 + 158 + 122 + 90 + 70 + 69 + 62 + 44 + 44)/3000,3)*100`
%.

* only "Universal Pictures", "Paramount Pictures" and "Walt Disney Pictures" contribute approximate 27% of total revenue.

* 2.1% movies which were missing Production company information, had negative ROI (-0.547).

### **cast**

A movie could have many casts, each `cast` represented by following text "{'cast_id': 4, 'character': 'Lou', 'credit_id': '52fe4ee7c3a36847f82afae7', 'gender': 2, 'id': 52997, 'name': '$\color{red}{\text{Rob Corddry}}$', 'order': 0, 'profile_path': '/k2zJL0V1nEZuFT08xUdOd3ucfXz.jpg'}". ($\color{red}{\text{red text}}$ is informative)

**Number of cast per movies**

To explore the correlation between number of cast per movies and the revenue, I added a new feature named n_cast to summarize the number of cast of a movie. In case missing value, I replaced by median.

```{r}
# create feature n_cast to summarize number of cast per movie
df$n_cast <- str_count(df$cast, pattern = "name")

# replace NA value by median.
df$n_cast[is.na(df$n_cast)] <- median(df$n_cast, na.rm = T)
```

```{r, fig.height=3.5, fig.width=3.5}
df %>% ggplot(aes(n_cast, revenue)) +
  geom_point(color = "steel blue",alpha = 0.5)
```

As we saw, the correlation between number of cast vs budget and/or revenue was not really high (0.3 and 0.34).

**Specific effect by leading actor/actress**

Normally in each movie, there was a leading actor, leading actress, star, or simply lead who plays the role of the protagonist of a film, television show or play. The word lead may also refer to the largest role in the piece and leading actor may refer to a person who typically plays such parts or an actor with a respected body of work.

We also know in practice, many people watch a movie just because the appearance of their idols or favor actors. To explore the correlation between the "leading actor/actress", I extracted name of the first and second casts into two feature `first_cast` and `second_cast`. 

```{r}
# extract the first cast
df$first_cast <- gsub("\\'\\,\\s\\'order\\'\\:\\s+0\\,.*",
                      "",
                      df$cast)
index <- str_which(df$first_cast,"profile")
df$first_cast <- gsub("\\'\\,\\s\\'order\\'\\:\\s+1\\,.*",
                      "",
                      df$first_cast)
df$first_cast <- str_extract(df$first_cast,"(?<=name\\'\\:\\s\\').+")
```

```{r}
# extract the second cast
df$second_cast <- gsub("\\'\\,\\s\\'order\\'\\:\\s{1}1\\,.*",
                      "",
                      df$cast)
df$second_cast <- gsub("\\[.*name\\'\\:\\s\\'","",
                       df$second_cast)
df$second_cast[index] <- gsub("\\'\\,\\s\\'order\\'\\:\\s{1}2\\,.*",
                      "",
                      df$cast)
df$second_cast[index] <- gsub("\\[.*name\\'\\:\\s\\'","",
                       df$second_cast)
```

```{r}
# create a summary table of first and second cast
cast_summary <- df %>% 
  select(first_cast, second_cast, revenue, budget) %>%
  gather(1:2, key = "cast_order", value = "cast_name")

cast_summary$cast_name <- gsub("\\'\\,.*","",cast_summary$cast_name)

cast_summary <- cast_summary %>%
  group_by(cast_name) %>%
  summarize(movies_per_cast = n(),
            avg_revenue_per_cast = mean(revenue, na.rm = T))

# remove all NA values
cast_summary <- na.omit(cast_summary)
```

```{r}
# visualize table
cast_summary %>% arrange(desc(movies_per_cast)) %>%
  head(10) %>%
  kable(caption = "Top 10 leading actor/actress all the time") %>%
  kable_styling(latex_options = c("HOLD_position","scale_down"), 
                position = "center", font_size = 10,
                bootstrap_options = c("striped", "hover"))
```

### **crew**

Crew contain the production team of a movie, each member represents by following strings "{'credit_id': '59ac067c92514107af02c8c8', 'department': 'Directing', 'gender': 0, 'id': 1449071, 'job': 'First Assistant Director', 'name': 'Kelly Cantley', 'profile_path': None}" and separate with other members by comma.

Because the length of strings is too long, I didn't copy it to this report.

Let's see how many members of a movies and explore its correlation to the movie's revenue.

```{r}
# calculate the number of crew per movie
df$n_crew <- str_count(df$crew, pattern = "name")

# replace NA value by median
df$n_crew[is.na(df$n_crew)] <- median(df$n_crew, na.rm = T)
```

```{r, fig.width=7, fig.height=3}
# visualize the frequency of number of crew and correlation between n_crew and revenue
grid.arrange(
  df %>% ggplot(aes(n_crew)) +
  geom_histogram(fill = "steel blue", color = "white") +
    labs(title = "number of crew"),
  
  df %>% ggplot(aes(n_crew, revenue)) +
    geom_point(color = "steel blue") +
    geom_smooth() + 
    labs(title = "revenue vs number of crew"),
  
  ncol = 2)
```

Looked like that there were low correlation between number of crew and revenue. The correlation was 
`r cor(df$revenue[1:3000], df$n_crew[1:3000])` which is not a high correlation.

### **production_countries**

Each country represent by following text "{'iso_3166_1': 'US', 'name': 'United States of America'}" and separate by comma.

```{r}
head(df$production_countries, 1)
```

Now we remove all unnecessary strings and keep only the country's name in the new feature `country`.

```{r}
# extract the first production country
df$country <- gsub("(\\[?\\{\\'iso\\_3166\\_1\\'\\:\\s{1}\\')|(\\'\\,\\s{1}\\'name.*\\}\\]?)","",df$production_countries)
df$country[is.na(df$country)] <- "no country info"

# create summary table by first production country
df %>% mutate(country = factor(country)) %>%
  group_by(country) %>%
  summarize(count = n()) %>% arrange(desc(count)) %>%
  head(15) %>%
  ggplot(aes(x = reorder(country, count), count, fill = count)) +
  labs(x = "country", title = "movies by production country") +
  geom_col() + coord_flip() + theme(legend.position = "none")
```

`r round(100*mean(df$country == "US"),1)`
movies produced in United State of America.

### **spoken_languages**

Let's take a look on top rows of `spoken_languages`.

```{r}
df$spoken_languages %>% head(1)
```

Each spoken language represent by following text "{'iso_639_1': 'en', 'name': 'English'}", only the $\color{red}{\text{red text}}$ is informative. We firstly create new feature `n_spoken_languages` represent for the number of spoken languages of a movie. Then we replace all unnecessary strings in the `spoken_languages`.

```{r}
# calculate number of spoken languages per movies
df$n_spoken_languages <- str_count(df$spoken_languages, pattern = "name")

# replace NA value by median
df$n_spoken_languages[is.na(df$n_spoken_languages)] <- median(df$n_spoken_languages, na.rm = T)
```

```{r, fig.width=6, fig.height=3}
grid.arrange(
  df %>% mutate(n_spoken_languages = factor(n_spoken_languages)) %>%
  ggplot(aes(n_spoken_languages)) +
  geom_bar(fill = "steel blue", color = "white") +
    theme_classic(),

df %>% mutate(n_spoken_languages = factor(n_spoken_languages)) %>%
  ggplot(aes(n_spoken_languages, revenue)) +
  geom_boxplot(fill = "light blue")+
  theme_classic(),
ncol = 2)
```

`r 100*round(mean(df$n_spoken_languages == 1),3)`
% movies have one spoken languages, another
`r 100*round(mean(df$n_spoken_languages == 2),3)`
% movies have two spoken languages, only 
`r 100 - 100*round(mean(df$n_spoken_languages <=2),3)`
% movies have more than two spoken languages.

# **Features engineering**

## **Normallized popularity**

From previous section, we known the period of time from first movie released date to the latest movie released date was 97 years. Furthermore, the popularity was calculated based on user interactions on the TMDb website, while the internet users and their time in internet increased by the time. To reduce the change across time, I added one more feature `normalized_popularity` by dividing `popularity` by the average popularity per release year. The calculation was as following:

```{r}
# create the summarized table for popularity
df$popularity <- df$new_popularity

popularity_sum <- df %>%
  group_by(release_year) %>%
  summarize(avg_popularity = mean(new_popularity, na.rm = T))
# create new normallized popularity
df <- df %>%
  left_join(popularity_sum, by = "release_year") %>%
  mutate(normallized_popularity = new_popularity/avg_popularity)
```

Adding second time normallized popularity feature.

```{r}
# create 2nd summarize table for normallized_popularity
norm_popularity_sum <- df %>%
  group_by(release_year) %>%
  summarize(max_norm_pop = max(normallized_popularity, na.rm = T))
# add 2nd normallized popularity
df <- df %>%
  left_join(norm_popularity_sum, by = "release_year") %>%
  mutate(second_norm_popularity = normallized_popularity/max_norm_pop)
```

## **Correlation and relationship between revenue and other variables**

To evaluate the correlation between revenue and budget, popularity, normallized_popularity... Also to explore the interaction between budget, popularity, normallized_popularity, I added new features includes:

  + `budget_pop` represent for interaction between budget and popularity.
  
  + `budget_norm_pop` represent for interaction between budget and normalized popularity.
  
  + `benefit` represent for the ratio between revenue and budget.
  
  + `profit` represent for the margin between revenue and budget.

```{r, fig.height=6.5, fig.width=6.5}
df$vote_average[is.na(df$vote_average)] <- mean(df$vote_average, na.rm = T)
df$vote_count[is.na(df$vote_count)] <- mean(df$vote_count, na.rm = T)

# create correlation plot between revenue, budget, popularity

corrplot(cor(df[1:3000,] %>% 
  # select separated variables
  select(revenue, new_budget, new_popularity, 
         new_runtime, normallized_popularity,
         vote_count, vote_average) %>%
 
   # to evaluate the correlation between variables
  mutate(budget_pop = new_budget*new_popularity,
         budget_norm_pop = new_budget*normallized_popularity,
         benefit = revenue/new_budget,
         profit = (revenue - new_budget))
),
type = "upper", method = "number")
```

We could see:

  + revenue is highest correlated to budget_pop (0.78), budget_norm_pop (0.77) and new_budget (0.74).
  
  + it's surprise that revenue/budget ratio seem not to correlate to any variables.
  
  + runtime seem not to correlate to revenue and other variables.
  
The following figures used to visualize the correlation between revenue vs budget, popularity:
  
```{r, fig.width=8,fig.height=3}
df %>% mutate(budget_norm_pop = new_budget*normallized_popularity) %>%
  select(revenue, new_popularity, budget, budget_norm_pop) %>%
  gather(2:4, key = "variables", value = "value") %>%
  ggplot(aes(value, revenue)) + 
  geom_point(color = "steel blue", alpha = 0.3) +
  geom_smooth() + facet_wrap(.~variables, ncol = 3, scales = "free")
```

The scatter between budget & revenue was more diffuse than the scatter between budget_norm_pop & revenue.
Therefore, I added new features named `budget_norm_pop` represent for the interaction between budget and normalized popularity.

```{r}
df <- df %>%
   # add correlation features between variables
  mutate(budget_pop = budget*new_popularity,
         budget_norm_pop = budget*normallized_popularity,
         squared_pop = normallized_popularity^2)
```

We could see one outlier in the popularity impact on the smooth fitting. The row index of this outlier could be determined by following code:

```{r}
# determine popularity outlier rows
which(df$new_popularity > 100)
```

Adding this outlier to vector outlier_rows.

```{r}
# add popularity outier rows to outlier_rows vector
outlier_rows <- c(outlier_rows, which(df$new_popularity > 100))
```

## **Genres**

From previous section, we known different genres had different average revenue. Furthermore one movie could have one or more genres. To add the effect by genres, I created 19 new features named by each genre. Each feature had two levels 0 and 1, which:

  + 0: if this genre didn't present in the genres list of movie
  
  + 1: if this genre present in the genres list of movie

```{r}
# create a vector contain all genre name
genres <- levels(factor(df$main_genre))
```

```{r}
# create features for each genre
for (i in 1:19){
  df[,genres[i]] <- ifelse(str_detect(df$genres,genres[i]),
                           1,0)
}
```

## **Top production companies**

From previous section, we know top production companies had many movies with possitive revenue compared to budget. 

```{r, fig.width=8}
grid.arrange(
first_company_summary %>% arrange(desc(movies_per_company)) %>% head(15) %>%
  mutate(first_company = reorder(first_company, movies_per_company)) %>%
  ggplot(aes(first_company, movies_per_company)) +
  geom_col(fill = "steel blue") + coord_flip(),

first_company_summary %>% arrange(desc(company_ranking)) %>% head(15) %>%
  mutate(first_company = reorder(first_company, company_ranking)) %>%
  ggplot(aes(first_company, company_ranking)) +
  geom_col(fill = "steel blue") + coord_flip(),

ncol = 2)
```

To add the effect by top 10 production companies, I created 10 new features named by each production company. Each feature had two levels 0 and 1, which:

  + 0: if the production company didn't present in the production companies list of movie
  
  + 1: if the production company present in the production companies list of movie
  
For other production companies did not belong to top 10 production companies, I assigned to a variables named "other_production_company", with similarly two levels 0 and 1.

```{r}
# create top production companies vector
top_production_companies <- first_company_summary %>% 
  arrange(desc(movies_per_company)) %>% head(10) %>%
  pull(first_company)

# create Dummy features for each production company
for (i in 1:length(top_production_companies)){
  df[,top_production_companies[i]] <- 
    ifelse(str_detect(df$production_companies,top_production_companies[i]),
                           1,0)
}

df$`no production companies info` <-
  ifelse(str_detect(df$companies, "no production companies info"),1,0)

from_company <- grep(head(top_production_companies,1), colnames(df))

to_company <- grep(tail(top_production_companies,1), colnames(df))

df$other_production_company <-
  ifelse(rowMeans((df[,from_company:to_company])) >0,0,1)

for (i in from_company:to_company){
  df[is.na(df[,i]),i] <- 0
}
```

## **Top production countries**

Create vector contain top production countries to add its effect to our model.

```{r}
top_countries <- c("US", "GB", "FR", "CA", "DE", "IN","no country info"
                   #"AU","JP","RU","ES","IT","CN"
                   )
```

```{r}
for (i in 1:length(top_countries)){
  df[,top_countries[i]] <-
    ifelse(str_detect(df$production_countries, top_countries[i]),
           1,0)
}

from_country <- grep(head(top_countries,1), colnames(df))
to_country <- grep(tail(top_countries,1), colnames(df))

df$other_production_countries <-
  ifelse(rowMeans((df[,from_country:to_country])) >0,0,1)
```

## **Top cast**

Create a vector contain top cast to add its effect to our model.

```{r}
top_cast <- cast_summary %>% 
  arrange(desc(movies_per_cast)) %>% head(50) %>%
  pull(cast_name)
```

```{r}
for (i in 1:length(top_cast)){
  df[,top_cast[i]] <-
    ifelse(str_detect(df$cast, top_cast[i]),
           1,0)
}

from_cast <- grep(head(top_cast,1), colnames(df))
to_cast <- grep(tail(top_cast,1), colnames(df))

df$other_cast <-
  ifelse(rowMeans((df[,from_cast:to_cast])) >0,0,1)
```

```{r}
cast_summary <- cast_summary %>%
  mutate(cast_rank = logb(avg_revenue_per_cast))
```


# **Modeling**

## **Design of experiment**

To evaluate the effect of each variables

  1) 

## **Logarit transformation and its effect**

To evaluate the effect of logarit in the RMSLE formula (based e), let's see how the ln effect on the number.

```{r}
plot(seq(1,1000000,1000), logb(seq(1,1000000,1000)))
```

The greater value, the  smaller return by logb function. The logb return greater when the x-value less than approx.
`r exp(11)`.

Since we have
`r sum(df$new_budget < 1000)` budget value less than 1000 and
`r sum(df$revenue[1:3000] < 1000)` revenue value less than 1000, those outlier have high effect on our model accuracy. For example, a simple wrong between true revenue and predict revenue by ln(100) - ln(1)  create big error by
`r logb(100) - logb(1)`.

## **Modeling concept**

**Insight from previous section**

Revenue is correlated to:
  + Budget
  + Popularity
  + 


## **Naive model**

My first try to use the average revenue as predicted revenue in test set. Let's see the RMSLE as below:

```{r}
naive_RMSLE <- RMSLE(average_revenue, test_y)
naive_RMSLE
```

## **Average profit ratio**

```{r}
avg_profit_ratio <- sum(df$revenue, na.rm = T)/sum(df$budget_norm_pop[1:3000])
avg_profit_ratio
```

```{r}
revenue_hat <- df$new_budget[3001:7398]*avg_profit_ratio

data.frame(RMSLE = RMSLE(revenue_hat, test_y),
           R_squared = cor(revenue_hat, test_y))
```


## **Average profit model by genres**

```{r}
genres_profit <- df[1:3000,] %>% group_by(main_genre) %>%
  summarize(avg_profit = sum(revenue)/sum(new_budget))
genres_profit
```

```{r}
revenue_hat <- df[3001:7398,] %>% left_join(genres_profit, by = "main_genre") 

revenue_hat <- revenue_hat %>%
  mutate(yhat = new_budget*avg_profit) %>% pull(yhat)

data.frame(RMSLE = RMSLE(revenue_hat, test_y),
           R_squared = cor(revenue_hat, test_y))

df <- df %>% mutate(based_revenue = new_budget*avg_profit_ratio)
```


## **Multi-variables model**

Second try using different machine learning methods (random forest, gradient boosting linear model, linear model, bayesian generalized linear model) to calculate predicted revenue. The model to calculate predicted revenue is summarized as following:

\begin{center}

predicted revenue = f(budget, popularity, budget * popularity, collection-effect, time-effect, genres-effect, production companies effect)

\end{center}

With:
  + budget, used `new_budget`
  + popularity, used `new_popularity` and `normallized_popularity`
  + budget * popularity, used `budget_norm_pop`
  + collection-effect, used `collection_status`
  + time-effect, used `release_year`, `release_month`, `weekday`
  + genres-effect, used $genre_{i}$
  + production companies effect, used top 10 production companies

The features were selected by following code:  
  
```{r selecting features,}
# calculate the column index of first genre and last genre 
from_genre <- grep("Action", colnames(df))
to_genre <- grep("Mystery", colnames(df))

# selecting features
dat <- df %>% 
   mutate(nOverview = nchar(overview),
         nKey = str_count(Keywords, pattern = "\\,")) %>%
  select(revenue,
         new_budget,
         based_revenue,
         budget_norm_pop,
         new_popularity, normallized_popularity,
         collection_status,
         release_year, release_month, weekday,
         number_of_company, 
         number_genres,
         from_genre:to_genre,(to_genre + 2):(to_genre + 7),
        from_company:to_company, to_company + 1,
      # from_country:to_country, to_country + 1,
     #  cast_rank
      # from_cast:to_cast
         )

# replace NA
for (i in 2:(ncol(dat))){
  dat[is.na(dat[,i]),i] <- median(dat[,i], na.rm = T)
}
```

Separate the full data df to train and test set and replace the outliers.

```{r}
# create train data
dat_train <- dat[1:3000,]

# replace outlier in train data
dat_train <- dat_train[c(-1231,-1680,-2859),]
dat_train <- filter(dat_train, new_budget > 1000 & revenue > 1000)

# create test data
dat_test <- dat[3001:7398,]
```

Before process modeling, we transform the revenue, budget by based logarit.

```{r}
for (i in 1:3){
  dat_train[,i] <- logb(dat_train[,i]+1)
  dat_test[,i] <- logb(dat_test[,i]+1)
}

head(dat)
```

The machine learning methods are randorm forest (rf), bayesian generalized linear model (bayesglm), gradient linear model boosting (glmboost) and linear model (lm) for modeling.

```{r, cache=TRUE}
# modeling with different methods
# NOTED: this process will take some minute

fit_rf <- train(revenue ~ ., 
             data = dat_train,
             method = "rf",
             importance = TRUE,
             verbose = TRUE,
             trControl = trainControl(method = "cv",
                                      number = 5,
                                      p = 0.8))
fit_bayesglm <- train(revenue~.,
                 data = dat_train,
                 method = "bayesglm",
                 trControl = trainControl(method = "cv",
                                      number = 5,
                                      p = 0.8))
fit_glmboost <- train(revenue~.,
                 data = dat_train,
                 method = "glmboost",
                 trControl = trainControl(method = "cv",
                                      number = 5,
                                      p = 0.8))
fit_lm <- train(revenue~.,
                 data = dat_train,
                 method = "lm",
                 trControl = trainControl(method = "cv",
                                      number = 5,
                                      p = 0.8))
```

Comparing performance by different method. Because Random forest seem to be better than others, I used this method as the final predicting model.

```{r}
data.frame(method = c("rf","bayesglm","glmboost","lm"),
           RMSLE =c(min(fit_rf$results$RMSE),
                    min(fit_bayesglm$results$RMSE),
                    min(fit_glmboost$results$RMSE),
                    min(fit_lm$results$RMSE)),
           Rsquared = c(max(fit_rf$results$Rsquared),
                        max(fit_bayesglm$results$Rsquared),
                        max(fit_glmboost$results$Rsquared),
                        max(fit_lm$results$Rsquared)))

```


# **Results & discussion**

## **Results**

Calculate the predicted revenue, using random forest model.

```{r}
# calculate predicted revenue
yhat_rf <- predict(fit_rf, newdata = dat_test)
```

Calculate the final RMSLE.

```{r}
RMSLE(yhat_rf, logb(test_y + 1))
```

This results is better than my expected target.

```{r}
yhat <- predict(fit_bayesglm, dat_test)
yhat[yhat <0] <- 3
RMSLE(yhat, test_y +1)
cor(yhat, test_y)
```



```{r, fig.height=7, fig.width=8}
library(randomForest)
randomForest::varImpPlot(fit_rf$finalModel)
```


